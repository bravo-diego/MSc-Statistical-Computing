{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa9d14a-0c4e-4878-88b4-a116d594d9a1",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239465e8-13c0-49ae-b4c7-89b94baa8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import log1p\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col, when, count \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39a667c-eb04-43e3-ac25-0d7149db72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .appName(\"Evaluating a Logistic Regression Model\")\\\n",
    "        .getOrCreate() # create a Spark session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97cfdc3a-e1db-4c6f-805b-1b5f497240a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Evaluating a Logistic Regression Model</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7aa12ffd7140>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark # spark session I've created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d106d0a-7ab9-447b-af03-627642ad7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/aspphem/Desktop/MCE/BigData/archive/breast-cancer.csv' # file path\n",
    "df = spark.read.option('header', 'true').csv(path, inferSchema = True) # read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690be92d-05db-4383-92fc-34c2302b45fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- diagnosis: string (nullable = true)\n",
      " |-- radius_mean: double (nullable = true)\n",
      " |-- texture_mean: double (nullable = true)\n",
      " |-- perimeter_mean: double (nullable = true)\n",
      " |-- area_mean: double (nullable = true)\n",
      " |-- smoothness_mean: double (nullable = true)\n",
      " |-- compactness_mean: double (nullable = true)\n",
      " |-- concavity_mean: double (nullable = true)\n",
      " |-- concave points_mean: double (nullable = true)\n",
      " |-- symmetry_mean: double (nullable = true)\n",
      " |-- fractal_dimension_mean: double (nullable = true)\n",
      " |-- radius_se: double (nullable = true)\n",
      " |-- texture_se: double (nullable = true)\n",
      " |-- perimeter_se: double (nullable = true)\n",
      " |-- area_se: double (nullable = true)\n",
      " |-- smoothness_se: double (nullable = true)\n",
      " |-- compactness_se: double (nullable = true)\n",
      " |-- concavity_se: double (nullable = true)\n",
      " |-- concave points_se: double (nullable = true)\n",
      " |-- symmetry_se: double (nullable = true)\n",
      " |-- fractal_dimension_se: double (nullable = true)\n",
      " |-- radius_worst: double (nullable = true)\n",
      " |-- texture_worst: double (nullable = true)\n",
      " |-- perimeter_worst: double (nullable = true)\n",
      " |-- area_worst: double (nullable = true)\n",
      " |-- smoothness_worst: double (nullable = true)\n",
      " |-- compactness_worst: double (nullable = true)\n",
      " |-- concavity_worst: double (nullable = true)\n",
      " |-- concave points_worst: double (nullable = true)\n",
      " |-- symmetry_worst: double (nullable = true)\n",
      " |-- fractal_dimension_worst: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() # print out the schema in tree format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9044151c-1219-477f-a02c-c5e5a178c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"diagnosis_no\", when(df['diagnosis'] == 'M', 1).otherwise(0)) # map the label to numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af843e-48d7-400a-8320-997798a12b28",
   "metadata": {},
   "source": [
    "## Building and Evaluating a Logistic Regression Model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d09ab8c4-883a-40ac-945f-996afe915ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols = [\"radius_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\"],\n",
    "    outputCol = \"features\"\n",
    ") # combine multiple features into a single vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1844642-7c98-44da-91a0-80e098b192cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_data = assembler.transform(df) # apply VectorAssembler to the dataframe\n",
    "train_data, test_data = assembled_data.randomSplit([0.8, 0.2], seed = 42) # split data in training data (80%) and test data (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73ffeaa-7e82-45e1-9f2d-c3399a127a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(featuresCol = 'features', labelCol = 'diagnosis_no') # define a log regression model\n",
    "logistic_reg_model = logistic_reg.fit(train_data) # fit the logistic regression model \n",
    "predictions = logistic_reg_model.transform(test_data) # apply model to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b74a08-707b-4ac5-b4c6-e805a3a9bc86",
   "metadata": {},
   "source": [
    "### Assessing Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "779d315a-1aaa-494f-86bd-964cf7a21f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9418604651162791\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol = \"diagnosis_no\", predictionCol = \"prediction\", metricName = \"accuracy\") # define an evaluator\n",
    "accuracy = evaluator.evaluate(predictions) # evaluate the model on test data\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59ea0a07-247a-4474-8fcd-bc3b7178747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------------+\n",
      "|diagnosis_no|prediction|            features|\n",
      "+------------+----------+--------------------+\n",
      "|           0|       0.0|[14.96,97.03,687....|\n",
      "|           0|       0.0|[12.18,77.79,451....|\n",
      "|           0|       0.0|[12.63,82.15,480....|\n",
      "|           0|       0.0|[10.8,68.77,357.6...|\n",
      "|           0|       0.0|[11.46,73.59,403....|\n",
      "|           1|       1.0|[23.51,155.1,1747...|\n",
      "|           1|       0.0|[14.6,93.97,664.7...|\n",
      "|           0|       0.0|[12.54,81.25,476....|\n",
      "|           1|       1.0|[13.0,87.5,519.8,...|\n",
      "|           1|       0.0|[16.02,102.7,797....|\n",
      "|           1|       1.0|[19.17,132.4,1123...|\n",
      "|           1|       1.0|[14.68,94.74,684....|\n",
      "|           1|       1.0|[21.16,137.2,1404...|\n",
      "|           1|       1.0|[18.61,122.1,1094...|\n",
      "|           1|       1.0|[16.74,110.1,869....|\n",
      "|           1|       1.0|[19.07,128.3,1104...|\n",
      "|           1|       1.0|[18.22,120.3,1033...|\n",
      "|           1|       1.0|[15.37,100.2,728....|\n",
      "|           1|       1.0|[13.11,87.21,530....|\n",
      "|           0|       0.0|[9.777,62.5,290.2...|\n",
      "+------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"diagnosis_no\", \"prediction\", \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1862ab2-b984-40b3-86e9-8627f76f217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop() # stop spark session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
