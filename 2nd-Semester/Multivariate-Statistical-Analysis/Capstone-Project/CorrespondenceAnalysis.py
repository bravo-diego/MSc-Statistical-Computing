# -*- coding: utf-8 -*-
"""CorrespondenceAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D9NkdfdNskuviT0gRXCzw9liyHI8aBUI

# Categorical Data: Correspondence analysis

### Encuesta Nacional de Calidad e Impacto Gubernamental (ENCIG) 2017
"""

!pip install dbfread

!pip install requests

!pip install ipywidgets

!pip install vegafusion[embed]>=1.5.0

"""#### Importar librerias necesarias"""

import io
import prince
import requests
import squarify
import geopandas

import numpy as np
import pandas as pd
import altair as alt
import seaborn as sns
import plotly.io as pio
import plotly.express as px
import matplotlib.pyplot as plt
import plotly.graph_objects as go

from dbfread import DBF
from sklearn.impute import KNNImputer

alt.data_transformers.enable("vegafusion") # habilita el transformador de datos 'vegafusion' para trabajar con conjuntos de datos >5000 filas

"""#### Cargar conjuntos de datos"""

def read_dbf_file(path):
    try:
        table = DBF(path, encoding = 'latin1', load = True) # leer archivo .dbf
        df = pd.DataFrame(iter(table)) # convertir tabla a dataframe
        print(df.keys()) # nombres de las columnas
        print(df.shape) # dimensiones del dataframe (filas, columnas)
        return df
    except Exception as e:
        print(f"An error occurred: {e}")

"""Tabla *encig2017_01_sec1_3_4_5_8_9_10* contiene informacion sobre los residentes de la vivienda y la identificacion de los hogares; percepcion de corrupcion; evaluacion de servicios basicos; evaluacion de servicios publicos bajo demanda; corrupcion y corrupcion general."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_01_sec1_3_4_5_8_9_10.dbf' # ubicacion del archivo .dbf
encig2017_01 = read_dbf_file(path)

"""Tabla *encig2017_02_residentes_sec_2* contiene informacion relacionada con los integrantes del hogar principal y las caracteristicas sociodemograficas."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_02_residentes_sec_2.dbf' # ubicacion del archivo .dbf
encig2017_02 = read_dbf_file(path)

"""Tabla *encig2017_03_sec_6* contiene informacion sobre las experiencias del informante seleccionado con los pagos, tramites y servicios publicos."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_03_sec_6.dbf' # ubicacion del archivo .dbf
encig2017_03 = read_dbf_file(path)

"""Tabla *encig2017_04_sec_7* contiene informacion relacionada con la calidad de los tramites y de los servicios publicos realizados de manera personal por el informante seleccionado."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_04_sec_7.dbf' # ubicacion del archivo .dbf
encig2017_04 = read_dbf_file(path)

"""Tabla *encig2017_05_sec_8* contiene informacion relacionada con la percepcion de corrupcion."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_05_sec_8.dbf' # ubicacion del archivo .dbf
encig2017_05 = read_dbf_file(path)

"""Tabla *encig2017_01_sec_11* contiene informacion relacionada con la confianza en las instituciones y actores diversos."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_01_sec_11.dbf' # ubicacion del archivo .dbf
encig2017_06 = read_dbf_file(path)

"""#### Estructura del conjunto de datos"""

encig2017_01.head() # primeras 5 filas del conjunto de datos

encig2017_01.tail() # ultimas 5 filas del conjunto de datos

encig2017_01.info() # informacion del conjunto de datos principal: no. entradas, no. columnas, tipos de datos, uso de memoria

encig2017_01.dtypes # tipos de datos para cada columna

encig2017_01.isnull().values.any() # comprobar si existe algun valor NaN en el dataframe

null_values = encig2017_01.isnull().sum()
encig2017_01.loc[:, null_values > 0] # filtrar columnas que tengan al menos un valor NaN

null_values = encig2017_01.isnull().sum(axis = 1)
encig2017_01[null_values > 0] # filtrar filas que tengan al menos un valor NaN

encig2017_01['NOM_ENT'].nunique() # verificar el no. de estados registrados en la base de datos

encig2017_01['NOM_ENT'].value_counts() # no. de encuestados por entidad federativa

"""#### Procesamiento del conjunto de datos

Tabla del hogar principal y de características del elegido: **secciones 1, 3, 4, 5, 8, 9, y 10.**
"""

sec_1_3_4_5_8_9_10 = encig2017_01.convert_dtypes().copy() # convertir datos para facilitar su manejo
sec_1_3_4_5_8_9_10.dtypes

sec_1_3_4_5_8_9_10.shape

sec_1_3_4_5_8_9_10['NOM_ENT'] = sec_1_3_4_5_8_9_10['NOM_ENT'].replace({'Aguascalientes': 'AGS', 'Baja California': 'BC', 'Baja California Sur': 'BCS', 'Campeche': 'CAMP', 'Coahuila de Zaragoza': 'COAH',
                                       'Colima': 'COL', 'Chiapas': 'CHIS', 'Chihuahua': 'CHIH', 'Ciudad de México': 'CDMX', 'Durango': 'DGO',
                                       'Guanajuato': 'GTO', 'Guerrero': 'GRO', 'Hidalgo': 'HGO', 'Jalisco': 'JAL', 'México': 'MEX',
                                       'Michoacán de Ocampo': 'MICH', 'Morelos': 'MOR', 'Nayarit': 'NAY', 'Nuevo León': 'NL', 'Oaxaca': 'OAX',
                                       'Puebla': 'PUE', 'Querétaro': 'QRO', 'Quintana Roo': 'QR', 'San Luis Potosí': 'SLP', 'Sinaloa': 'SIN',
                                       'Sonora': 'SON', 'Tabasco': 'TAB', 'Tamaulipas': 'TAM', 'Tlaxcala': 'TLAX', 'Veracruz de Ignacio de la Llave': 'VER',
                                       'Yucatán': 'YUC', 'Zacatecas': 'ZAC'}) # abreviar los nombres de las entidades federativas
sec_1_3_4_5_8_9_10['NOM_ENT'].unique()

sec_1_3_4_5_8_9_10['ENT'].unique()

sec_1_3_4_5_8_9_10.describe() # estadisticos generales del conjunto de datos

"""Tabla de confianza en las instituciones:  **sección 11**"""

sec_11 = encig2017_06.convert_dtypes().copy() # convertir datos para facilitar su manejo
sec_11.dtypes

sec_11.shape

sec_11['NOM_ENT'] = sec_11['NOM_ENT'].replace({'Aguascalientes': 'AGS', 'Baja California': 'BC', 'Baja California Sur': 'BCS', 'Campeche': 'CAMP', 'Coahuila de Zaragoza': 'COAH',
                                       'Colima': 'COL', 'Chiapas': 'CHIS', 'Chihuahua': 'CHIH', 'Ciudad de México': 'CDMX', 'Durango': 'DGO',
                                       'Guanajuato': 'GTO', 'Guerrero': 'GRO', 'Hidalgo': 'HGO', 'Jalisco': 'JAL', 'México': 'MEX',
                                       'Michoacán de Ocampo': 'MICH', 'Morelos': 'MOR', 'Nayarit': 'NAY', 'Nuevo León': 'NL', 'Oaxaca': 'OAX',
                                       'Puebla': 'PUE', 'Querétaro': 'QRO', 'Quintana Roo': 'QR', 'San Luis Potosí': 'SLP', 'Sinaloa': 'SIN',
                                       'Sonora': 'SON', 'Tabasco': 'TAB', 'Tamaulipas': 'TAM', 'Tlaxcala': 'TLAX', 'Veracruz de Ignacio de la Llave': 'VER',
                                       'Yucatán': 'YUC', 'Zacatecas': 'ZAC'}) # abreviar los nombres de las entidades federativas
sec_11['NOM_ENT'].unique()

sec_11.describe() # estadisticos generales del conjunto de datos

"""Tabla de seguimiento de trámites, pagos o servicios públicos: **sección 7**"""

sec_7 = encig2017_04.convert_dtypes().copy() # convertir datos para facilitar su manejo
sec_7.dtypes

sec_7.shape

sec_7['NOM_ENT'] = sec_7['NOM_ENT'].replace({'Aguascalientes': 'AGS', 'Baja California': 'BC', 'Baja California Sur': 'BCS', 'Campeche': 'CAMP', 'Coahuila de Zaragoza': 'COAH',
                                             'Colima': 'COL', 'Chiapas': 'CHIS', 'Chihuahua': 'CHIH', 'Ciudad de México': 'CDMX', 'Durango': 'DGO',
                                             'Guanajuato': 'GTO', 'Guerrero': 'GRO', 'Hidalgo': 'HGO', 'Jalisco': 'JAL', 'México': 'MEX',
                                             'Michoacán de Ocampo': 'MICH', 'Morelos': 'MOR', 'Nayarit': 'NAY', 'Nuevo León': 'NL', 'Oaxaca': 'OAX',
                                             'Puebla': 'PUE', 'Querétaro': 'QRO', 'Quintana Roo': 'QR', 'San Luis Potosí': 'SLP', 'Sinaloa': 'SIN',
                                             'Sonora': 'SON', 'Tabasco': 'TAB', 'Tamaulipas': 'TAM', 'Tlaxcala': 'TLAX', 'Veracruz de Ignacio de la Llave': 'VER',
                                             'Yucatán': 'YUC', 'Zacatecas': 'ZAC'}) # abreviar los nombres de las entidades federativas
sec_7['NOM_ENT'].unique()

sec_7.describe() # estadisticos generales del conjunto de datos

"""## Principales Problemáticas de Cada Entidad Federativa en la República Mexicana"""

columns = list(range(20, 32)) # columnas de interes: problemas a los que se enfrentan los estados

updated_names = ['Desempeno_Gub', 'Pobreza', 'Corrupcion', 'Desempleo', 'Inseguridad',
                'Aplicacion_Ley', 'Desastres_Naturales', 'Educacion', 'Salud', 'Coordinacion_Gub',
                'Rendicion_Cuentas', 'Ninguno', 'Entidad_Federativa'] # redefinir nombre de las variables de acuerdo al diccionario de datos de la base de datos

country_main_issues = sec_1_3_4_5_8_9_10.iloc[:, columns].astype(int).copy() # conversion de string a int
country_main_issues['NOM_ENT'] = sec_1_3_4_5_8_9_10['NOM_ENT'] # agregar columna con los nombres de las entidades federativas actualizados
country_main_issues.columns = updated_names # actualizar el nombre de las variables
country_main_issues.head()

country_main_issues.dtypes # verificar los tipos de datos del dataframe

contingency_table_main_issues = country_main_issues.groupby('Entidad_Federativa').sum() # agrupar observaciones por estado
contingency_table_main_issues.head()

contingency_table_main_issues.shape

"""#### Percepción de la Ocurrencia de las Principales Problemáticas en la República Mexicana"""

main_issues = ['Desempeño Gubernamental', 'Pobreza', 'Corrupción', 'Desempleo', 'Inseguridad',
                'Mala Aplicación de la Ley', 'Medio Ambiente', 'Educación', 'Salud', 'Coordinación Gubernamental',
                'Rendición de Cuentas', 'Ninguno'] # problematicas principales que enfrentan las entidades federativas
frecuency_main_issues = contingency_table_main_issues.copy()
frecuency_main_issues.columns = main_issues # redefinir las columnas para mejor la legibilidad de los graficos
frecuency_main_issues = frecuency_main_issues.reset_index()

frecuency_main_issues.head()

frecuency_main_issues = pd.melt(frecuency_main_issues, id_vars=['Entidad_Federativa'], value_vars = main_issues,
                                var_name = 'Ploblematica', value_name = 'Frecuencia')
frecuency_main_issues

frecuency_main_issues['Ploblematica'].unique() # problematicas principales que enfrentan las entidades federativas

frecuency_main_issues['Entidad_Federativa'].unique() # entidades federativas

frecuency_by_states = frecuency_main_issues.drop(['Entidad_Federativa'], axis = 1).groupby(['Ploblematica']).sum().reset_index().copy()
frecuency_by_states

"""#### Distribución Visual de las Principales Problemáticas en la República Mexicana"""

fig = plt.gcf()
ax = fig.add_subplot()
fig.set_size_inches(16, 8)

squarify.plot(sizes = frecuency_by_states['Frecuencia'], label = frecuency_by_states['Ploblematica'],
              color = sns.color_palette('PuBu_r', len(frecuency_by_states['Frecuencia'])), alpha = .7) # treemap generado utilizando la libreria squarify

plt.axis('off')
plt.savefig('Treemap.png')
plt.show()

"""El treemap muestra cómo se distribuyen las principales problemáticas entre la población, destacando la gravedad de cada problemática en términos de su frecuencia reportada. Los dos problemas principales que afectan a la poblacion son en temas de **seguridad**, con una frecuencia de 27,869, y **corrupción**, con 21,520 casos. Estas problemáticas están representadas como las áreas más grandes en el treemap.

Las categorías **Ninguno** y **Medio Ambiente** son las menos frecuentes, con solo 132 y 1,054 casos, respectivamente. Estas ocupan la menor área en el treemap.

#### Análisis de Correspondencia

El análisis de correspondencia se realiza para explorar y visualizar las relaciones entre las filas y columnas de una tabla de contingencia. En este caso, la tabla de contingencia *contingency_table_main_issues* muestra la frecuencia de ocurrencia de diferentes problemáticas (columnas) en las distintas entidades federativas (filas). En este contexto, se pretende analizar la asociación entre las problemáticas y las entidades federativas.
"""

ca = prince.CA(n_components = 3, n_iter = 3, copy = True,
               check_input = True, engine = 'sklearn', random_state = 0) # modelo de analisis de correspondencia
ca = ca.fit(contingency_table_main_issues) # ajustar el modelo a los datos

ca.eigenvalues_summary

"""Las dos primeras componentes explican más del **60% de la varianza total**."""

ca.plot(contingency_table_main_issues, x_component = 0, y_component = 1, show_row_markers = True,
        show_column_markers = False, show_row_labels = False, show_column_labels = True)

ca.plot(contingency_table_main_issues, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = False)

ca.plot(contingency_table_main_issues, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = True)

ca.column_contributions_.style.format('{:.0%}')

ca.row_contributions_.style.format('{:.0%}')

"""## Percepción de la Corrupción"""

columns = list(range(32, 54)) # columnas de interes: variables relacionadas a la percepcion de la corrupcion

updated_names = ['Percepcion', 'Universidades', 'Policia', 'Hospitales', 'Secretarias',
                'Empresarios', 'Gubernatura', 'Trabajo', 'Municipio', 'Familiares',
                'Sindicatos', 'Vecinos', 'Diputados_Senadores', 'Medios_Comunicacion', 'Intitutos_Electorales',
                'Comisiones_Derechos', 'Escuelas_Publicas', 'Jueces_Magistrados', 'Insituciones_Religiosas', 'Partidos_Politicos',
                'Ejercito_Marina', 'Ministerio_Publico', 'Entidad_Federativa'] # redefinir nombre de las variables de acuerdo al diccionario de datos de la base de datos

corruption = sec_1_3_4_5_8_9_10 .iloc[:, columns].astype(int).copy() # conversion de string a int
corruption['NOM_ENT'] = sec_1_3_4_5_8_9_10 ['NOM_ENT'] # agregar columna con los nombres de las entidades federativas actualizados
corruption.columns = updated_names # actualizar el nombre de las variables
corruption.head()

corruption.dtypes # verificar los tipos de datos del conjunto de datos

"""### Percepción de la Corrupción en las Entidades Federativas"""

corruption_perception = corruption.loc[:, ['Entidad_Federativa', 'Percepcion']].copy() # percepcion de la corrupcion por entidad federativa
corruption_perception['Percepcion'] = corruption_perception['Percepcion'].replace({1: 'Muy_Frecuente', 2: 'Frecuente', 3: 'Poco_Frecuente',
                                                                                  4: 'Nada_Frecuente', 9: 'No_Sabe'}) # reemplazar el valor numerico por la categoria correspondiente

corruption_perception.head()

contingency_table_corruption_perception = corruption_perception.pivot_table(index = 'Entidad_Federativa', columns = 'Percepcion', aggfunc = len, fill_value = 0) # agrupar observaciones por estado y contar no. de ocurrencias de cada nivel de percepcion
contingency_table_corruption_perception.head()

"""Para obtener una medida del nivel de percepción de la corrupción por entidad federativa, se unieron las categorías **Muy Frecuente** y **Frecuente** en una sola, indicando la *presencia de corrupción*. De igual manera, se combinaron las categorías **Nada Frecuente** y **Poco Frecuente** en una sola, indicando la *ausencia de corrupción*. Las respuestas de la categoría **No sabe/No responde** fueron descartadas, ya que no aportan información relevante sobre la percepción de corrupción."""

average_level_corruption = contingency_table_corruption_perception.drop(['No_Sabe'], axis = 1).copy() # eliminar variable No Sabe/Responde

average_level_corruption['Presencia'] = average_level_corruption['Muy_Frecuente'] + average_level_corruption['Frecuente'] # variable Presencia incluye observaciones de las categorias Muy Frecuente y Frecuente
average_level_corruption['Ausencia'] = average_level_corruption['Poco_Frecuente'] + average_level_corruption['Nada_Frecuente'] # variable Ausencia incluye observaciones de las categorias Poco Frecuente y Nada Frecuente
average_level_corruption['Total'] = average_level_corruption['Ausencia'] + average_level_corruption['Presencia'] # no. total de observaciones
average_level_corruption['Porcentaje'] = ((average_level_corruption['Presencia'] / average_level_corruption['Total'])*100).round(2) # porcentaje del nivel de percepcion de corrupcion por entidad federativa

average_level_corruption = average_level_corruption.iloc[:, 4:]
average_level_corruption.head()

barplot_corruption = average_level_corruption.reset_index().rename(columns = {'Entidad_Federativa': 'Entidad Federativa'}).copy()

pio.renderers.default = 'iframe'
fig = px.bar(barplot_corruption, x = 'Entidad Federativa', y = 'Porcentaje')
fig.update_layout(xaxis = {'categoryorder':'total descending'})
fig.update_traces(marker_color = 'indianred', marker_line_color = 'brown', marker_line_width = 1.5, opacity = 0.6)
fig.update_layout(title_text = 'Nivel de Percepción de la Corrupción por Entidad Federativa')
fig.show()

"""En general, todas las entidades federativas muestran un **alto porcentaje de percepción de corrupción**, con valores que oscilan entre el 76.51% y el 96.45%. Esto sugiere que la corrupción es percibida como un **problema significativo** en todas las entidades federativas. Aunque existe variación entre las entidades federativas, todas muestran una preocupación considerablemente alta por la corrupción en comparación con la ausencia de esta.

### Panorama General de la Percepción de la Corrupción en México
"""

geographical_data_mx = geopandas.read_file("https://gist.githubusercontent.com/walkerke/76cb8cc5f949432f9555/raw/363c297ce82a4dcb9bdf003d82aa4f64bc695cf1/mx.geojson")
geographical_data_mx.head() # conjunto de datos geográficos de México

geographical_data_mx['state'].unique() # nombres de las entidades federativas registradas en el conjunto de datos geograficos

geographical_data_mx['state'] = geographical_data_mx['state'].replace({'Aguascalientes': 'AGS', 'Baja California': 'BC', 'Baja California Sur': 'BCS', 'Campeche': 'CAMP', 'Coahuila de Zaragoza': 'COAH',
                                'Colima': 'COL', 'Chiapas': 'CHIS', 'Chihuahua': 'CHIH', 'Distrito Federal': 'CDMX', 'Durango': 'DGO',
                                'Guanajuato': 'GTO', 'Guerrero': 'GRO', 'Hidalgo': 'HGO', 'Jalisco': 'JAL', 'México': 'MEX',
                                'Michoacán de Ocampo': 'MICH', 'Morelos': 'MOR', 'Nayarit': 'NAY', 'Nuevo León': 'NL', 'Oaxaca': 'OAX',
                                'Puebla': 'PUE', 'Querétaro': 'QRO', 'Quintana Roo': 'QR', 'San Luis Potosí': 'SLP', 'Sinaloa': 'SIN',
                                'Sonora': 'SON', 'Tabasco': 'TAB', 'Tamaulipas': 'TAM', 'Tlaxcala': 'TLAX', 'Veracruz de Ignacio de la Llave': 'VER',
                                'Yucatán': 'YUC', 'Zacatecas': 'ZAC'}) # abreviación de los nombres de las entidades federativas para garantizar compatibilidad entre los conjuntos de datos
geographical_data_mx['state'].unique() # verificar cambio

corruption_data = average_level_corruption.reset_index().copy()
corruption_data = corruption_data.loc[:, ['Entidad_Federativa', 'Porcentaje']] # columnas de interes: entidades federativas y porcentaje de percepción de corrupción por entidad federativa
names = ['state', 'percent']
corruption_data.columns = names

corruption_map = pd.merge(geographical_data_mx, corruption_data, how = 'inner', on = ['state']) # unir conjunto de datos geograficos con el conjunto de datos de corrupcion apartir de la columna compartida 'state'

corruption_map.head(2)

corruption_map.dtypes

ax = corruption_map.plot(column = 'percent', cmap = 'OrRd', legend = True,
                        legend_kwds = {"label": "Nivel de Percepción de la Corrupción", "orientation": "horizontal"})
ax.set_axis_off()
fig = ax.get_figure()
fig.savefig('NivelCorrupción.png')

"""La percepción de corrupción en México es generalizada, con un **alto porcentaje** en todas las entidades federativas. Todas las regiones muestran preocupaciones considerables en cuanto a la corrupción.

#### Análisis de Correspondencia

Se llevó a cabo un análisis de correspondencia utilizando la tabla de contingencia *contingency_table_corruption_perception* con el fin de entender la relación entre la percepción de corrupción y las entidades federativas. Se busca identificar patrones o relaciones entre las percepciones de corrupción y las regiones geográficas representadas por las entidades federativas.
"""

ca = prince.CA(n_components = 3, n_iter = 3, copy = True,
               check_input = True, engine = 'sklearn', random_state = 0) # modelo de analisis de correspondencia
ca = ca.fit(contingency_table_corruption_perception) # ajustar el modelo a los datos

ca.eigenvalues_summary

"""Las dos primeras componentes explican más del **90% de la varianza total**."""

ca.plot(contingency_table_corruption_perception, x_component = 0, y_component = 1, show_row_markers = True,
        show_column_markers = False, show_row_labels = False, show_column_labels = True)

ca.plot(contingency_table_corruption_perception, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = False)

ca.plot(contingency_table_corruption_perception, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = True)

ca.column_contributions_.style.format('{:.0%}')

ca.row_contributions_.style.format('{:.0%}')

"""### Percepción de la Corrupción en Instituciones Públicas"""

corruption_per_institution = corruption.iloc[:, 1:22].copy() # percepcion de la corrupcion por entidad federativa
corruption_per_institution = corruption_per_institution.replace({1: 'Muy_Frecuente', 2: 'Frecuente', 3: 'Poco_Frecuente',
                                                                 4: 'Nada_Frecuente', 9: 'No_Sabe'}) # reemplazar el valor numerico por la categoria correspondiente

corruption_per_institution.head()

corruption_per_institution.columns # insituciones publicas

categories = ['Muy_Frecuente', 'Frecuente', 'Poco_Frecuente', 'Nada_Frecuente', 'No_Sabe'] # niveles de percepcion de la corrupcion
contingency_table_corruption_insitutes = pd.DataFrame(columns = categories) # no. ocurrencias de cada nivel de percepcion en las distintas instituciones publicas
contingency_table_corruption_insitutes.head() # conjunto de datos vacio

for column in corruption_per_institution.columns:
    frecuency = corruption_per_institution[column].value_counts().reindex(categories, fill_value = 0).to_dict() # ocurrencias de los distintos niveles de percepcion de la corrupcion (categorias) para las distintas instituciones
    contingency_table_corruption_insitutes = pd.concat([contingency_table_corruption_insitutes, pd.DataFrame(frecuency, index = [column])]) # anadir fila (institucion) con el no. de ocurrencias para las distintas categorias (columnas)

contingency_table_corruption_insitutes.head()

contingency_table_corruption_insitutes.dtypes # verificar los tipos de datos de la tabla de contingencia

contingency_table_corruption_insitutes[categories] = contingency_table_corruption_insitutes[categories].astype(int) # conversion de object a int
contingency_table_corruption_insitutes.dtypes # verificar los tipos de datos de la tabla de contingencia

"""#### Análisis de Correspondencia

En este caso el análisis de correspondencia nos ayudaría a identificar patrones y relaciones entre la percepción de corrupción y las diferentes instituciones públicas, lo que proporcionaría información valiosa para comprender mejor la dinámica de la corrupción en el sector público y orientar esfuerzos para combatirla.
"""

ca = prince.CA(n_components = 3, n_iter = 3, copy = True,
               check_input = True, engine = 'sklearn', random_state = 0) # modelo de analisis de correspondencia
ca = ca.fit(contingency_table_corruption_insitutes) # ajustar el modelo a los datos

ca.eigenvalues_summary

"""Las dos primeras componentes explican más del **90% de la varianza total**."""

ca.plot(contingency_table_corruption_insitutes, x_component = 0, y_component = 1, show_row_markers = True,
        show_column_markers = False, show_row_labels = False, show_column_labels = True)

ca.plot(contingency_table_corruption_insitutes, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = False)

ca.plot(contingency_table_corruption_insitutes, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = True)

ca.column_contributions_.style.format('{:.0%}')

ca.row_contributions_.style.format('{:.0%}')

"""### Percepción de la Corrupción y su Relación con la Confianza Ciudadana en las Instituciones Publicas

#### Nivel de Percepción de la Corrupción en las Instituciones Públicas
"""

id_corruption = sec_1_3_4_5_8_9_10.loc[:, ['ENT', 'UPM', 'V_SEL', 'P3_2', 'P3_3_1', 'P3_3_2', 'P3_3_3', 'P3_3_4', 'P3_3_5',
                           'P3_3_6', 'P3_3_7', 'P3_3_8', 'P3_3_9', 'P3_3_10', 'P3_3_11', 'P3_3_12', 'P3_3_13', 'P3_3_14',
                           'P3_3_15', 'P3_3_16', 'P3_3_17', 'P3_3_18', 'P3_3_19', 'P3_3_20', 'P3_3_21']].copy() # conjunto de datos con las variables relacionadas al nivel de percepcion de corrupcion hacia instituciones manteniendo variables compartidas ENT, UPM, y V_SEL

id_corruption.shape # dimensiones del conjunto de datos

id_corruption.head()

id_corruption.dtypes

id_corruption.iloc[:, list(range(3, 25))] = id_corruption.iloc[:, list(range(3, 25))].apply(pd.to_numeric, errors = 'coerce').astype('int64') # conversion de tipos de datos string a int
id_corruption.dtypes # verificar los tipos de datos del conjunto de datos

id_corruption = id_corruption.replace({1: 'Muy_Frecuente', 2: 'Frecuente', 3: 'Poco_Frecuente',
                                       4: 'Nada_Frecuente', 9: 'No_Sabe'}) # reemplazar el valor numerico por la categoria correspondiente

id_corruption.head()

id_corruption.tail()

"""#### Nivel de Confianza Ciudadana en las Instituciones Públicas"""

trust_confidence_public_institutes = sec_11.loc[:, ['ENT', 'UPM', 'V_SEL', 'P11_1_1', 'P11_1_2', 'P11_1_3', 'P11_1_4', 'P11_1_5', 'P11_1_6',
               'P11_1_7', 'P11_1_8', 'P11_1_9', 'P11_1_10', 'P11_1_11', 'P11_1_12', 'P11_1_13', 'P11_1_14',
               'P11_1_15', 'P11_1_16', 'P11_1_17', 'P11_1_18','P11_1_19', 'P11_1_20', 'P11_1_21']].copy() # conjunto de datos con las variables relacionadas al nivel de confianza hacia instituciones manteniendo variables compartidas ENT, UPM, y V_SEL

trust_confidence_public_institutes.shape # dimensiones del conjunto de datos

trust_confidence_public_institutes.head()

trust_confidence_public_institutes.dtypes

trust_confidence_public_institutes.iloc[:, list(range(3, 24))] = trust_confidence_public_institutes.iloc[:, list(range(3, 24))].apply(pd.to_numeric, errors = 'coerce').astype('int64') # conversion de tipos de datos string a int
trust_confidence_public_institutes.dtypes # verificar los tipos de datos del conjunto de datos

trust_confidence_public_institutes = trust_confidence_public_institutes.replace({1: 'Mucha_Confianza', 2: 'Poca_Confianza', 3: 'Desconfianza',
                                                                                 4: 'Mucha_Desconfianza', 5: 'No_Aplica', 9: 'No_Responde'}) # reemplazar el valor numerico por la categoria correspondiente

trust_confidence_public_institutes

"""#### Relación entre los Niveles de Percepción de la Corrupción y Confianza en las Instituciones Públicas"""

corruption_confidence_insitutes = pd.merge(id_corruption, trust_confidence_public_institutes,
                                           how = 'inner', on = ['ENT', 'UPM', 'V_SEL']) # combinar los conjuntos de datos utilizando las variables compartidas ENT, UPM, y V_SEL

corruption_confidence_insitutes.head()

corruption_confidence_insitutes.dtypes

corruption_and_confidence = corruption_confidence_insitutes.iloc[:, list(range(4, 46))].copy() # conjunto de datos con las variables relacionadas a la percepcion de la corrupcion y al nivel de confianza hacia las instituciones publicas

corruption_and_confidence.columns

corruption_and_confidence.head()

categories = ['Muy_Frecuente', 'Frecuente', 'Poco_Frecuente', 'Nada_Frecuente', 'No_Sabe',
              'Mucha_Confianza', 'Poca_Confianza', 'Desconfianza', 'Mucha_Desconfianza', 'No_Aplica', 'No_Responde'] # niveles de percepcion de la corrupcion y confianza hacias las instituciones publicas
contingency_table_corruption_confidence = pd.DataFrame(columns = categories) # no. ocurrencias de cada nivel de percepcion en las distintas instituciones publicas
contingency_table_corruption_confidence.head() # conjunto de datos vacio

for column in corruption_and_confidence.columns:
    frecuency = corruption_and_confidence[column].value_counts().reindex(categories, fill_value = 0).to_dict() # ocurrencias de los distintos niveles de percepcion de la corrupcion (categorias) para las distintas instituciones
    contingency_table_corruption_confidence = pd.concat([contingency_table_corruption_confidence, pd.DataFrame(frecuency, index = [column])]) # anadir fila (institucion) con el no. de ocurrencias para las distintas categorias (columnas)

contingency_table_corruption_confidence.dtypes # verificar los tipos de datos de la tabla de contingencia

contingency_table_corruption_confidence[categories] = contingency_table_corruption_confidence[categories].astype(int) # conversion de object a int
contingency_table_corruption_confidence.dtypes # verificar los tipos de datos de la tabla de contingencia

contingency_table_corruption_confidence.head()

contingency_table_corruption_confidence.tail()

categories = {'P3_3_1': 'Universidades', 'P3_3_2': 'Policia', 'P3_3_3': 'Hospitales', 'P3_3_4': 'Secretarias', 'P3_3_5': 'Empresarios', 'P3_3_6': 'Gubernatura', 'P3_3_7': 'Trabajo', 'P3_3_8': 'Municipio', 'P3_3_9': 'Familiares', 'P3_3_10': 'Sindicatos', 'P3_3_11': 'Vecinos', 'P3_3_12': 'Diputados_Senadores', 'P3_3_13': 'Medios_Comunicacion', 'P3_3_14': 'Intitutos_Electorales', 'P3_3_15': 'Comisiones_Derechos', 'P3_3_16': 'Escuelas_Publicas', 'P3_3_17': 'Jueces_Magistrados', 'P3_3_18': 'Insituciones_Religiosas', 'P3_3_19': 'Partidos_Politicos', 'P3_3_20': 'Ejercito_Marina', 'P3_3_21': 'Ministerio_Publico',
              'P11_1_1': 'Universidades', 'P11_1_2': 'Policia', 'P11_1_3': 'Hospitales', 'P11_1_4': 'Secretarias', 'P11_1_5': 'Empresarios', 'P11_1_6': 'Gubernatura', 'P11_1_7': 'Trabajo', 'P11_1_8': 'Municipio', 'P11_1_9': 'Familiares', 'P11_1_10': 'Sindicatos', 'P11_1_11': 'Vecinos', 'P11_1_12': 'Diputados_Senadores', 'P11_1_13': 'Medios_Comunicacion', 'P11_1_14': 'Intitutos_Electorales', 'P11_1_15': 'Comisiones_Derechos', 'P11_1_16': 'Escuelas_Publicas', 'P11_1_17': 'Jueces_Magistrados', 'P11_1_18': 'Insituciones_Religiosas', 'P11_1_19': 'Partidos_Politicos', 'P11_1_20': 'Ejercito_Marina', 'P11_1_21': 'Ministerio_Publico'} # variables y sus instituciones asociadas correspondientes

contingency_table_corruption_confidence = contingency_table_corruption_confidence.rename(categories) # reemplazar el nombre de la variable por la institucion correspondiente
contingency_table_corruption_confidence

contingency_table_corruption_confidence.columns

agg_functions = {'Muy_Frecuente': 'sum', 'Frecuente': 'sum', 'Poco_Frecuente': 'sum', 'Nada_Frecuente': 'sum',
                 'No_Sabe': 'sum', 'Mucha_Confianza': 'sum', 'Poca_Confianza': 'sum', 'Desconfianza': 'sum',
                 'Mucha_Desconfianza': 'sum', 'No_Aplica': 'sum', 'No_Responde': 'sum'}

contingency_table_corruption_confidence_updated = contingency_table_corruption_confidence.groupby(contingency_table_corruption_confidence.index).agg(agg_functions) # agrupar frecuencias de cada categoria (columnas) para cada institucion (filas)
contingency_table_corruption_confidence_updated

contingency_table_corruption_confidence_updated.dtypes # verificar los tipos de datos de la tabla de contingencia

"""#### Análisis de Correspondencia"""

ca = prince.CA(n_components = 3, n_iter = 3, copy = True,
               check_input = True, engine = 'sklearn', random_state = 0) # modelo de analisis de correspondencia
ca = ca.fit(contingency_table_corruption_confidence_updated) # ajustar el modelo a los datos

ca.eigenvalues_summary

"""Las dos primeras componentes explican más del **80% de la varianza total**."""

ca.plot(contingency_table_corruption_confidence_updated, x_component = 0, y_component = 1, show_row_markers = True,
        show_column_markers = False, show_row_labels = False, show_column_labels = True)

ca.plot(contingency_table_corruption_confidence_updated, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = False)

ca.plot(contingency_table_corruption_confidence_updated, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = True)

ca.column_contributions_.style.format('{:.0%}')

ca.row_contributions_.style.format('{:.0%}')

"""## Experiencias con Pagos, Tramites y Solicitudes de Servicios Basicos"""

services_and_corruption = sec_1_3_4_5_8_9_10.loc[:, ['ENT', 'NOM_ENT', 'UPM', 'V_SEL', 'P8_2', 'P9_1', 'P9_7', 'P9_8']].copy() # columnas de interes correspondientes a los casos de corrupcion reportados por los ciudadanos

services_provided = sec_7.loc[:, ['ENT', 'NOM_ENT', 'UPM', 'V_SEL', 'N_TRA', 'P7_4_1', 'P7_4_2', 'P7_4_3', 'P7_4_4', 'P7_4_5',
                                 'P7_4_6', 'P7_4_7', 'P7_4_8', 'P7_4_9', 'P7_4_10', 'P7_4_11']] # columnas de interes correspondientes a los problemas principales que enfrenta la poblacion al momento de realizar un tramite de algun servicio

services_provided = services_provided.set_index('NOM_ENT')
services_provided.head()

services_provided.dtypes

services_updated = services_provided.loc[((services_provided['N_TRA'] != '20') | (services_provided['N_TRA'] == '19')) & (services_provided['N_TRA'] != '21') &
                                         ((services_provided['N_TRA'] != '22a') & (services_provided['N_TRA'] != '22b') & (services_provided['N_TRA'] != '22c') & (services_provided['N_TRA'] != '22d'))].copy() # excluir trámites realizados por medios telefónicos

services_updated

services_updated = services_updated.iloc[:, 4:]
services_updated.head()

issues_related_services = ['Largas Filas', 'Falta de Claridad', 'Requisitos Excesivos', 'Ventanilla Incorrecta', 'Informacion Erronea',
                           'Fallas Telefonicas', 'Fallas Servicio en Linea', 'Lejania del Sitio', 'Costo Excesivo', 'Horario Restringido', 'Otro'] # instituciones publicas
services_updated.columns = issues_related_services

services_updated = services_updated.replace({'1': 'Si', '2': 'No', '3': 'No Aplica',
                                             '9': 'Indiferente', 'b': 'Sin Informacion'}) # reemplazar el valor numerico por la categoria correspondiente

services_updated

"""#### Problemas con Pagos, Trámites y Solicitudes de Servicios Públicos"""

categories = ['Si', 'No', 'No Aplica', 'Indiferente', 'Sin Informacion'] # posibles respuestas hacia la problematica en cuestion
contingency_table_issues_related_services = pd.DataFrame(columns = categories) # no. ocurrencias de cada nivel de percepcion en las distintas instituciones publicas
contingency_table_issues_related_services.head() # conjunto de datos vacio

for column in services_updated.columns:
    frecuency = services_updated[column].value_counts().reindex(categories, fill_value = 0).to_dict() # ocurrencias de los distintos niveles de percepcion de la corrupcion (categorias) para las distintas instituciones
    contingency_table_issues_related_services = pd.concat([contingency_table_issues_related_services, pd.DataFrame(frecuency, index = [column])]) # anadir fila (institucion) con el no. de ocurrencias para las distintas categorias (columnas)

contingency_table_issues_related_services[categories] = contingency_table_issues_related_services[categories].astype(int) # conversion de object a int
contingency_table_issues_related_services.dtypes # verificar los tipos de datos de la tabla de contingencia

contingency_table_issues_related_services

contingency_table_issues_related_services_updated = contingency_table_issues_related_services.drop(columns=['Sin Informacion'])

"""#### Análisis de Correspondencia"""

ca = prince.CA(n_components = 3, n_iter = 3, copy = True,
               check_input = True, engine = 'sklearn', random_state = 0) # modelo de analisis de correspondencia
ca = ca.fit(contingency_table_issues_related_services_updated) # ajustar el modelo a los datos

ca.eigenvalues_summary

ca.plot(contingency_table_issues_related_services_updated, x_component = 0, y_component = 1, show_row_markers = True,
        show_column_markers = False, show_row_labels = False, show_column_labels = True)

ca.plot(contingency_table_issues_related_services_updated, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = False)

ca.plot(contingency_table_issues_related_services_updated, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels =True)

contingency_table_issues_related_services = contingency_table_issues_related_services.iloc[:, :2]
contingency_table_issues_related_services['Total'] = contingency_table_issues_related_services.sum(axis = 1) # agregar columna con el total de entradas por fila

contingency_table_issues_related_services['% Si'] = (contingency_table_issues_related_services['Si'] / contingency_table_issues_related_services['Total']) * 100
contingency_table_issues_related_services['% No'] = (contingency_table_issues_related_services['No'] / contingency_table_issues_related_services['Total']) * 100
contingency_table_issues_related_services = contingency_table_issues_related_services.reset_index().sort_values(by = '% Si', ascending = False)

contingency_table_issues_related_services

pio.renderers.default = 'iframe'

colors = ['lightslategray'] * 11
colors[0] = 'brown'
colors[1] = 'brown'
colors[2] = 'brown'

fig = go.Figure()
fig.add_trace(go.Bar(
    x = contingency_table_issues_related_services['index'],
    y = contingency_table_issues_related_services['% Si'],
    name = 'Frecuencia de Ocurrencia del Problema',
    marker_color = colors,
    opacity = 0.6
))

fig.update_layout(title_text = 'Problemas en el Pago, Trámite o Solicitud de Servicios Públicos')
fig.update_layout(barmode = 'group', bargroupgap = 0.10, bargap = 0.20)
bargroupgap=0.1
fig.show()

"""El problema predominante en los pagos, trámites o solicitudes de servicios públicos es la espera en **largas filas** al momento de realizarlos. Le sigue una **falta de claridad** en los requisitos y la existencia de **horarios restringidos**. Esto es de vital importancia, ya que la mayoría de la población mexicana no cuenta con el tiempo necesario para afrontar largos períodos de espera durante los breves horarios de atención, generalmente limitados a días laborables de 8 am a 3 pm, lo que choca con los horarios laborales habituales de la ciudadanía.

El segundo problema más común es la **falta de claridad** en los requisitos solicitados, lo cual está relacionado con lo mencionado anteriormente. Dado que los días disponibles para resolver este tipo de problemas son limitados, el rechazo de un trámite debido a un requisito erróneo puede convertirse en un inconveniente que requiere atención en la mayoría de las instituciones públicas del país.

### Consideraciones Finales

El análisis de correspondencia simple (CA) es una herramienta muy útil para trabajar con datos categóricos. En este caso, **los gráficos obtenidos a partir del CA respaldan los resultados del análisis descriptivo de los datos**. Por lo tanto, la aplicación eficiente y la comprensión de este método, así como de su extensión, el Análisis de Correspondencia Múltiple (MCA), resultan de gran ayuda para obtener resultados significativos y visuales facilitando el manejo y el entendimiento de grandes conjuntos de datos.
"""