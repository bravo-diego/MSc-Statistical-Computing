# -*- coding: utf-8 -*-
"""AnalisisDatosCategoricos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1suXYytIfR7oRWVSlEJKKmHeMLByMl5AU

# Análisis de Datos Categóricos para Estadísticas Oficiales

### *Encuesta Nacional de Calidad e Impacto Gubernamental 2017*

*Datos Categóricos - Corrupción - Desempeño Gubernamental - Análisis de Correspondencia - Análisis de Correspondencia Múltiple*
"""

!pip install dbfread

!pip install squarify

!pip install requests

!pip install ipywidgets

!pip install vegafusion[embed]>=1.5.0

"""#### Importar librerias necesarias"""

import io
import prince
import requests
import squarify
import geopandas

import numpy as np
import pandas as pd
import altair as alt
import seaborn as sns
import plotly.io as pio
import plotly.express as px
import matplotlib.pyplot as plt
import plotly.graph_objects as go

from dbfread import DBF
from sklearn.impute import KNNImputer
from ydata_profiling import ProfileReport
from IPython.display import FileLink, display

alt.data_transformers.enable("vegafusion") # habilita el transformador de datos 'vegafusion' para trabajar con conjuntos de datos >5000 filas

"""#### Cargar conjuntos de datos"""

def read_dbf_file(path):
    try:
        table = DBF(path, encoding = 'latin1', load = True) # leer archivo .dbf
        df = pd.DataFrame(iter(table)) # convertir tabla a dataframe
        print(df.keys()) # nombres de las columnas
        print(df.shape) # dimensiones del dataframe (filas, columnas)
        return df
    except Exception as e:
        print(f"An error occurred: {e}")

"""Tabla *encig2017_01_sec1_3_4_5_8_9_10* contiene informacion sobre los residentes de la vivienda y la identificacion de los hogares; percepcion de corrupcion; evaluacion de servicios basicos; evaluacion de servicios publicos bajo demanda; corrupcion y corrupcion general."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_01_sec1_3_4_5_8_9_10.dbf' # ubicacion del archivo .dbf
encig2017_01 = read_dbf_file(path)

"""Tabla *encig2017_02_residentes_sec_2* contiene informacion relacionada con los integrantes del hogar principal y las caracteristicas sociodemograficas."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_02_residentes_sec_2.dbf' # ubicacion del archivo .dbf
encig2017_02 = read_dbf_file(path)

"""Tabla *encig2017_03_sec_6* contiene informacion sobre las experiencias del informante seleccionado con los pagos, tramites y servicios publicos."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_03_sec_6.dbf' # ubicacion del archivo .dbf
encig2017_03 = read_dbf_file(path)

"""Tabla *encig2017_04_sec_7* contiene informacion relacionada con la calidad de los tramites y de los servicios publicos realizados de manera personal por el informante seleccionado."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_04_sec_7.dbf' # ubicacion del archivo .dbf
encig2017_04 = read_dbf_file(path)

"""Tabla *encig2017_05_sec_8* contiene informacion relacionada con la percepcion de corrupcion."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_05_sec_8.dbf' # ubicacion del archivo .dbf
encig2017_05 = read_dbf_file(path)

"""Tabla *encig2017_01_sec_11* contiene informacion relacionada con la confianza en las instituciones y actores diversos."""

path = '/home/aspphem/Desktop/MCE/DataScience/Project/Analisis datos categoricos/encig17_base_datos_dbf/encig2017_01_sec_11.dbf' # ubicacion del archivo .dbf
encig2017_06 = read_dbf_file(path)

"""#### Estructura del conjunto de datos"""

encig2017_01.head() # primeras 5 filas del conjunto de datos

encig2017_01.tail() # ultimas 5 filas del conjunto de datos

encig2017_01.info() # informacion del conjunto de datos principal: no. entradas, no. columnas, tipos de datos, uso de memoria

encig2017_01.dtypes # tipos de datos para cada columna

encig2017_01.isnull().values.any() # comprobar si existe algun valor NaN en el dataframe

null_values = encig2017_01.isnull().sum()
encig2017_01.loc[:, null_values > 0] # filtrar columnas que tengan al menos un valor NaN

null_values = encig2017_01.isnull().sum(axis = 1)
encig2017_01[null_values > 0] # filtrar filas que tengan al menos un valor NaN

encig2017_01['NOM_ENT'].nunique() # verificar el no. de estados registrados en la base de datos

encig2017_01['NOM_ENT'].value_counts() # no. de encuestados por entidad federativa

"""#### Procesamiento del conjunto de datos

Tabla del hogar principal y de características del elegido: **secciones 1, 3, 4, 5, 8, 9, y 10.**
"""

sec_1_3_4_5_8_9_10 = encig2017_01.convert_dtypes().copy() # convertir datos para facilitar su manejo
sec_1_3_4_5_8_9_10.dtypes

sec_1_3_4_5_8_9_10.shape

sec_1_3_4_5_8_9_10['NOM_ENT'] = sec_1_3_4_5_8_9_10['NOM_ENT'].replace({'Aguascalientes': 'AGS', 'Baja California': 'BC', 'Baja California Sur': 'BCS', 'Campeche': 'CAMP', 'Coahuila de Zaragoza': 'COAH',
                                       'Colima': 'COL', 'Chiapas': 'CHIS', 'Chihuahua': 'CHIH', 'Ciudad de México': 'CDMX', 'Durango': 'DGO',
                                       'Guanajuato': 'GTO', 'Guerrero': 'GRO', 'Hidalgo': 'HGO', 'Jalisco': 'JAL', 'México': 'MEX',
                                       'Michoacán de Ocampo': 'MICH', 'Morelos': 'MOR', 'Nayarit': 'NAY', 'Nuevo León': 'NL', 'Oaxaca': 'OAX',
                                       'Puebla': 'PUE', 'Querétaro': 'QRO', 'Quintana Roo': 'QR', 'San Luis Potosí': 'SLP', 'Sinaloa': 'SIN',
                                       'Sonora': 'SON', 'Tabasco': 'TAB', 'Tamaulipas': 'TAM', 'Tlaxcala': 'TLAX', 'Veracruz de Ignacio de la Llave': 'VER',
                                       'Yucatán': 'YUC', 'Zacatecas': 'ZAC'}) # abreviar los nombres de las entidades federativas
sec_1_3_4_5_8_9_10['NOM_ENT'].unique()

sec_1_3_4_5_8_9_10['ENT'].unique()

sec_1_3_4_5_8_9_10.describe() # estadisticos generales del conjunto de datos

"""Tabla de confianza en las instituciones:  **sección 11**"""

sec_11 = encig2017_06.convert_dtypes().copy() # convertir datos para facilitar su manejo
sec_11.dtypes

sec_11.shape

sec_11['NOM_ENT'] = sec_11['NOM_ENT'].replace({'Aguascalientes': 'AGS', 'Baja California': 'BC', 'Baja California Sur': 'BCS', 'Campeche': 'CAMP', 'Coahuila de Zaragoza': 'COAH',
                                       'Colima': 'COL', 'Chiapas': 'CHIS', 'Chihuahua': 'CHIH', 'Ciudad de México': 'CDMX', 'Durango': 'DGO',
                                       'Guanajuato': 'GTO', 'Guerrero': 'GRO', 'Hidalgo': 'HGO', 'Jalisco': 'JAL', 'México': 'MEX',
                                       'Michoacán de Ocampo': 'MICH', 'Morelos': 'MOR', 'Nayarit': 'NAY', 'Nuevo León': 'NL', 'Oaxaca': 'OAX',
                                       'Puebla': 'PUE', 'Querétaro': 'QRO', 'Quintana Roo': 'QR', 'San Luis Potosí': 'SLP', 'Sinaloa': 'SIN',
                                       'Sonora': 'SON', 'Tabasco': 'TAB', 'Tamaulipas': 'TAM', 'Tlaxcala': 'TLAX', 'Veracruz de Ignacio de la Llave': 'VER',
                                       'Yucatán': 'YUC', 'Zacatecas': 'ZAC'}) # abreviar los nombres de las entidades federativas
sec_11['NOM_ENT'].unique()

sec_11.describe() # estadisticos generales del conjunto de datos

"""Tabla de seguimiento de trámites, pagos o servicios públicos: **sección 7**"""

sec_7 = encig2017_04.convert_dtypes().copy() # convertir datos para facilitar su manejo
sec_7.dtypes

sec_7.shape

sec_7['NOM_ENT'] = sec_7['NOM_ENT'].replace({'Aguascalientes': 'AGS', 'Baja California': 'BC', 'Baja California Sur': 'BCS', 'Campeche': 'CAMP', 'Coahuila de Zaragoza': 'COAH',
                                             'Colima': 'COL', 'Chiapas': 'CHIS', 'Chihuahua': 'CHIH', 'Ciudad de México': 'CDMX', 'Durango': 'DGO',
                                             'Guanajuato': 'GTO', 'Guerrero': 'GRO', 'Hidalgo': 'HGO', 'Jalisco': 'JAL', 'México': 'MEX',
                                             'Michoacán de Ocampo': 'MICH', 'Morelos': 'MOR', 'Nayarit': 'NAY', 'Nuevo León': 'NL', 'Oaxaca': 'OAX',
                                             'Puebla': 'PUE', 'Querétaro': 'QRO', 'Quintana Roo': 'QR', 'San Luis Potosí': 'SLP', 'Sinaloa': 'SIN',
                                             'Sonora': 'SON', 'Tabasco': 'TAB', 'Tamaulipas': 'TAM', 'Tlaxcala': 'TLAX', 'Veracruz de Ignacio de la Llave': 'VER',
                                             'Yucatán': 'YUC', 'Zacatecas': 'ZAC'}) # abreviar los nombres de las entidades federativas
sec_7['NOM_ENT'].unique()

sec_7.describe() # estadisticos generales del conjunto de datos

"""#### Resumen del Conjunto de Datos Principal Utilizando Pandas Profiling"""

file_profile = "profiles/MFC_profile_short.html"
profile = ProfileReport(sec_1_3_4_5_8_9_10, title = 'Data Summary ENCIG 2017 Survey')

profile.to_file('ENCIG2017.html') # guardar reporte como archivo html

"""## Principales Problemáticas de Cada Entidad Federativa en la República Mexicana"""

columns = list(range(20, 32)) # columnas de interes: problemas a los que se enfrentan los estados

updated_names = ['Desempeno_Gub', 'Pobreza', 'Corrupcion', 'Desempleo', 'Inseguridad',
                'Aplicacion_Ley', 'Desastres_Naturales', 'Educacion', 'Salud', 'Coordinacion_Gub',
                'Rendicion_Cuentas', 'Ninguno', 'Entidad_Federativa'] # redefinir nombre de las variables de acuerdo al diccionario de datos de la base de datos

country_main_issues = sec_1_3_4_5_8_9_10.iloc[:, columns].astype(int).copy() # conversion de string a int
country_main_issues['NOM_ENT'] = sec_1_3_4_5_8_9_10['NOM_ENT'] # agregar columna con los nombres de las entidades federativas actualizados
country_main_issues.columns = updated_names # actualizar el nombre de las variables
country_main_issues.head()

country_main_issues.dtypes # verificar los tipos de datos del dataframe

contingency_table_main_issues = country_main_issues.groupby('Entidad_Federativa').sum() # agrupar observaciones por estado
contingency_table_main_issues.head()

contingency_table_main_issues.shape

"""#### Percepción de la Ocurrencia de las Principales Problemáticas en la República Mexicana"""

main_issues = ['Desempeño Gubernamental', 'Pobreza', 'Corrupción', 'Desempleo', 'Inseguridad',
                'Mala Aplicación de la Ley', 'Medio Ambiente', 'Educación', 'Salud', 'Coordinación Gubernamental',
                'Rendición de Cuentas', 'Ninguno'] # problematicas principales que enfrentan las entidades federativas
frecuency_main_issues = contingency_table_main_issues.copy()
frecuency_main_issues.columns = main_issues # redefinir las columnas para mejor la legibilidad de los graficos
frecuency_main_issues = frecuency_main_issues.reset_index()

frecuency_main_issues.head()

frecuency_main_issues = pd.melt(frecuency_main_issues, id_vars=['Entidad_Federativa'], value_vars = main_issues,
                                var_name = 'Ploblematica', value_name = 'Frecuencia')
frecuency_main_issues

frecuency_main_issues['Ploblematica'].unique() # problematicas principales que enfrentan las entidades federativas

frecuency_main_issues['Entidad_Federativa'].unique() # entidades federativas

frecuency_by_states = frecuency_main_issues.drop(['Entidad_Federativa'], axis = 1).groupby(['Ploblematica']).sum().reset_index().copy()
frecuency_by_states

"""#### Distribución Visual de las Principales Problemáticas en la República Mexicana"""

fig = plt.gcf()
ax = fig.add_subplot()
fig.set_size_inches(16, 8)

squarify.plot(sizes = frecuency_by_states['Frecuencia'], label = frecuency_by_states['Ploblematica'],
              color = sns.color_palette('PuBu_r', len(frecuency_by_states['Frecuencia'])), alpha = .7) # treemap generado utilizando la libreria squarify

plt.axis('off')
plt.show()

"""El treemap muestra cómo se distribuyen las principales problemáticas entre la población, destacando la gravedad de cada problemática en términos de su frecuencia reportada. Los dos problemas principales que afectan a la poblacion son en temas de **seguridad**, con una frecuencia de 27,869, y **corrupción**, con 21,520 casos. Estas problemáticas están representadas como las áreas más grandes en el treemap.

Las categorías **Ninguno** y **Medio Ambiente** son las menos frecuentes, con solo 132 y 1,054 casos, respectivamente. Estas ocupan la menor área en el treemap.

#### Análisis de Correspondencia

El análisis de correspondencia se realiza para explorar y visualizar las relaciones entre las filas y columnas de una tabla de contingencia. En este caso, la tabla de contingencia *contingency_table_main_issues* muestra la frecuencia de ocurrencia de diferentes problemáticas (columnas) en las distintas entidades federativas (filas). En este contexto, se pretende analizar la asociación entre las problemáticas y las entidades federativas.
"""

ca = prince.CA(n_components = 3, n_iter = 3, copy = True,
               check_input = True, engine = 'sklearn', random_state = 0) # modelo de analisis de correspondencia
ca = ca.fit(contingency_table_main_issues) # ajustar el modelo a los datos

ca.eigenvalues_summary

"""Las dos primeras componentes explican más del **60% de la varianza total**."""

ca.plot(contingency_table_main_issues, x_component = 0, y_component = 1, show_row_markers = True,
        show_column_markers = False, show_row_labels = False, show_column_labels = True)

ca.plot(contingency_table_main_issues, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = False)

ca.plot(contingency_table_main_issues, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = True)

ca.column_contributions_.style.format('{:.0%}')

ca.row_contributions_.style.format('{:.0%}')

"""## Percepción de la Corrupción"""

columns = list(range(32, 54)) # columnas de interes: variables relacionadas a la percepcion de la corrupcion

updated_names = ['Percepcion', 'Universidades', 'Policia', 'Hospitales', 'Secretarias',
                'Empresarios', 'Gubernatura', 'Trabajo', 'Municipio', 'Familiares',
                'Sindicatos', 'Vecinos', 'Diputados_Senadores', 'Medios_Comunicacion', 'Intitutos_Electorales',
                'Comisiones_Derechos', 'Escuelas_Publicas', 'Jueces_Magistrados', 'Insituciones_Religiosas', 'Partidos_Politicos',
                'Ejercito_Marina', 'Ministerio_Publico', 'Entidad_Federativa'] # redefinir nombre de las variables de acuerdo al diccionario de datos de la base de datos

corruption = sec_1_3_4_5_8_9_10 .iloc[:, columns].astype(int).copy() # conversion de string a int
corruption['NOM_ENT'] = sec_1_3_4_5_8_9_10 ['NOM_ENT'] # agregar columna con los nombres de las entidades federativas actualizados
corruption.columns = updated_names # actualizar el nombre de las variables
corruption.head()

corruption.dtypes # verificar los tipos de datos del conjunto de datos

"""### Percepción de la Corrupción en las Entidades Federativas"""

corruption_perception = corruption.loc[:, ['Entidad_Federativa', 'Percepcion']].copy() # percepcion de la corrupcion por entidad federativa
corruption_perception['Percepcion'] = corruption_perception['Percepcion'].replace({1: 'Muy_Frecuente', 2: 'Frecuente', 3: 'Poco_Frecuente',
                                                                                  4: 'Nada_Frecuente', 9: 'No_Sabe'}) # reemplazar el valor numerico por la categoria correspondiente

corruption_perception.head()

contingency_table_corruption_perception = corruption_perception.pivot_table(index = 'Entidad_Federativa', columns = 'Percepcion', aggfunc = len, fill_value = 0) # agrupar observaciones por estado y contar no. de ocurrencias de cada nivel de percepcion
contingency_table_corruption_perception.head()

"""Para obtener una medida del nivel de percepción de la corrupción por entidad federativa, se unieron las categorías **Muy Frecuente** y **Frecuente** en una sola, indicando la *presencia de corrupción*. De igual manera, se combinaron las categorías **Nada Frecuente** y **Poco Frecuente** en una sola, indicando la *ausencia de corrupción*. Las respuestas de la categoría **No sabe/No responde** fueron descartadas, ya que no aportan información relevante sobre la percepción de corrupción."""

average_level_corruption = contingency_table_corruption_perception.drop(['No_Sabe'], axis = 1).copy() # eliminar variable No Sabe/Responde

average_level_corruption['Presencia'] = average_level_corruption['Muy_Frecuente'] + average_level_corruption['Frecuente'] # variable Presencia incluye observaciones de las categorias Muy Frecuente y Frecuente
average_level_corruption['Ausencia'] = average_level_corruption['Poco_Frecuente'] + average_level_corruption['Nada_Frecuente'] # variable Ausencia incluye observaciones de las categorias Poco Frecuente y Nada Frecuente
average_level_corruption['Total'] = average_level_corruption['Ausencia'] + average_level_corruption['Presencia'] # no. total de observaciones
average_level_corruption['Porcentaje'] = ((average_level_corruption['Presencia'] / average_level_corruption['Total'])*100).round(2) # porcentaje del nivel de percepcion de corrupcion por entidad federativa

average_level_corruption = average_level_corruption.iloc[:, 4:]
average_level_corruption.head()

barplot_corruption = average_level_corruption.reset_index().rename(columns = {'Entidad_Federativa': 'Entidad Federativa'}).copy()

pio.renderers.default = 'iframe'
fig = px.bar(barplot_corruption, x = 'Entidad Federativa', y = 'Porcentaje')
fig.update_layout(xaxis = {'categoryorder':'total descending'})
fig.update_traces(marker_color = 'indianred', marker_line_color = 'brown', marker_line_width = 1.5, opacity = 0.6)
fig.update_layout(title_text = 'Nivel de Percepción de la Corrupción por Entidad Federativa')
fig.show()

"""En general, todas las entidades federativas muestran un **alto porcentaje de percepción de corrupción**, con valores que oscilan entre el 76.51% y el 96.45%. Esto sugiere que la corrupción es percibida como un **problema significativo** en todas las entidades federativas. Aunque existe variación entre las entidades federativas, todas muestran una preocupación considerablemente alta por la corrupción en comparación con la ausencia de esta.

### Panorama General de la Percepción de la Corrupción en México
"""

geographical_data_mx = geopandas.read_file("https://gist.githubusercontent.com/walkerke/76cb8cc5f949432f9555/raw/363c297ce82a4dcb9bdf003d82aa4f64bc695cf1/mx.geojson")
geographical_data_mx.head() # conjunto de datos geográficos de México

geographical_data_mx['state'].unique() # nombres de las entidades federativas registradas en el conjunto de datos geograficos

geographical_data_mx['state'] = geographical_data_mx['state'].replace({'Aguascalientes': 'AGS', 'Baja California': 'BC', 'Baja California Sur': 'BCS', 'Campeche': 'CAMP', 'Coahuila de Zaragoza': 'COAH',
                                'Colima': 'COL', 'Chiapas': 'CHIS', 'Chihuahua': 'CHIH', 'Distrito Federal': 'CDMX', 'Durango': 'DGO',
                                'Guanajuato': 'GTO', 'Guerrero': 'GRO', 'Hidalgo': 'HGO', 'Jalisco': 'JAL', 'México': 'MEX',
                                'Michoacán de Ocampo': 'MICH', 'Morelos': 'MOR', 'Nayarit': 'NAY', 'Nuevo León': 'NL', 'Oaxaca': 'OAX',
                                'Puebla': 'PUE', 'Querétaro': 'QRO', 'Quintana Roo': 'QR', 'San Luis Potosí': 'SLP', 'Sinaloa': 'SIN',
                                'Sonora': 'SON', 'Tabasco': 'TAB', 'Tamaulipas': 'TAM', 'Tlaxcala': 'TLAX', 'Veracruz de Ignacio de la Llave': 'VER',
                                'Yucatán': 'YUC', 'Zacatecas': 'ZAC'}) # abreviación de los nombres de las entidades federativas para garantizar compatibilidad entre los conjuntos de datos
geographical_data_mx['state'].unique() # verificar cambio

corruption_data = average_level_corruption.reset_index().copy()
corruption_data = corruption_data.loc[:, ['Entidad_Federativa', 'Porcentaje']] # columnas de interes: entidades federativas y porcentaje de percepción de corrupción por entidad federativa
names = ['state', 'percent']
corruption_data.columns = names

corruption_map = pd.merge(geographical_data_mx, corruption_data, how = 'inner', on = ['state']) # unir conjunto de datos geograficos con el conjunto de datos de corrupcion apartir de la columna compartida 'state'

corruption_map.head(2)

corruption_map.dtypes

ax = corruption_map.plot(column = 'percent', cmap = 'OrRd', legend = True,
                        legend_kwds = {"label": "Nivel de Percepción de la Corrupción", "orientation": "horizontal"})
ax.set_axis_off()
fig = ax.get_figure()
fig.savefig('NivelCorrupción.png')

"""La percepción de corrupción en México es generalizada, con un **alto porcentaje** en todas las entidades federativas. Todas las regiones muestran preocupaciones considerables en cuanto a la corrupción.

#### Análisis de Correspondencia

Se llevó a cabo un análisis de correspondencia utilizando la tabla de contingencia *contingency_table_corruption_perception* con el fin de entender la relación entre la percepción de corrupción y las entidades federativas. Se busca identificar patrones o relaciones entre las percepciones de corrupción y las regiones geográficas representadas por las entidades federativas.
"""

ca = prince.CA(n_components = 3, n_iter = 3, copy = True,
               check_input = True, engine = 'sklearn', random_state = 0) # modelo de analisis de correspondencia
ca = ca.fit(contingency_table_corruption_perception) # ajustar el modelo a los datos

ca.eigenvalues_summary

"""Las dos primeras componentes explican más del **90% de la varianza total**."""

ca.plot(contingency_table_corruption_perception, x_component = 0, y_component = 1, show_row_markers = True,
        show_column_markers = False, show_row_labels = False, show_column_labels = True)

ca.plot(contingency_table_corruption_perception, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = False)

ca.plot(contingency_table_corruption_perception, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = True)

ca.column_contributions_.style.format('{:.0%}')

ca.row_contributions_.style.format('{:.0%}')

"""### Percepción de la Corrupción en Instituciones Públicas"""

corruption_per_institution = corruption.iloc[:, 1:22].copy() # percepcion de la corrupcion por entidad federativa
corruption_per_institution = corruption_per_institution.replace({1: 'Muy_Frecuente', 2: 'Frecuente', 3: 'Poco_Frecuente',
                                                                 4: 'Nada_Frecuente', 9: 'No_Sabe'}) # reemplazar el valor numerico por la categoria correspondiente

corruption_per_institution.head()

corruption_per_institution.columns # insituciones publicas

categories = ['Muy_Frecuente', 'Frecuente', 'Poco_Frecuente', 'Nada_Frecuente', 'No_Sabe'] # niveles de percepcion de la corrupcion
contingency_table_corruption_insitutes = pd.DataFrame(columns = categories) # no. ocurrencias de cada nivel de percepcion en las distintas instituciones publicas
contingency_table_corruption_insitutes.head() # conjunto de datos vacio

for column in corruption_per_institution.columns:
    frecuency = corruption_per_institution[column].value_counts().reindex(categories, fill_value = 0).to_dict() # ocurrencias de los distintos niveles de percepcion de la corrupcion (categorias) para las distintas instituciones
    contingency_table_corruption_insitutes = pd.concat([contingency_table_corruption_insitutes, pd.DataFrame(frecuency, index = [column])]) # anadir fila (institucion) con el no. de ocurrencias para las distintas categorias (columnas)

contingency_table_corruption_insitutes.head()

contingency_table_corruption_insitutes.dtypes # verificar los tipos de datos de la tabla de contingencia

contingency_table_corruption_insitutes[categories] = contingency_table_corruption_insitutes[categories].astype(int) # conversion de object a int
contingency_table_corruption_insitutes.dtypes # verificar los tipos de datos de la tabla de contingencia

"""#### Análisis de Correspondencia

En este caso el análisis de correspondencia nos ayudaría a identificar patrones y relaciones entre la percepción de corrupción y las diferentes instituciones públicas, lo que proporcionaría información valiosa para comprender mejor la dinámica de la corrupción en el sector público y orientar esfuerzos para combatirla.
"""

ca = prince.CA(n_components = 3, n_iter = 3, copy = True,
               check_input = True, engine = 'sklearn', random_state = 0) # modelo de analisis de correspondencia
ca = ca.fit(contingency_table_corruption_insitutes) # ajustar el modelo a los datos

ca.eigenvalues_summary

"""Las dos primeras componentes explican más del **90% de la varianza total**."""

ca.plot(contingency_table_corruption_insitutes, x_component = 0, y_component = 1, show_row_markers = True,
        show_column_markers = False, show_row_labels = False, show_column_labels = True)

ca.plot(contingency_table_corruption_insitutes, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = False)

ca.plot(contingency_table_corruption_insitutes, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = True)

ca.column_contributions_.style.format('{:.0%}')

ca.row_contributions_.style.format('{:.0%}')

"""#### Análisis de Correspondencia Múltiple

El **Análisis de Correspondencia Múltiple** es una técnica estadística utilizada para explorar las relaciones entre múltiples variables categóricas en un conjunto de datos. Es una extensión del enfoque del análisis de correspondencia simple, que se utiliza cuando se tienen más de dos variables categóricas para analizar.

Realizar un análisis de correspondencia múltiple utilizando el conjunto de datos *corruption* nos ayudaría a comprender la relación entre la percepción de corrupción y las distintas instituciones públicas en todo el país. Esto nos proporcionaría una visión completa de cómo la percepción de corrupción varía entre diferentes tipos de instituciones en diferentes regiones del país.
"""

corruption_mx = corruption.iloc[:, 1:23].set_index('Entidad_Federativa').copy() # percepción de corrupción en las instituciones públicas por entidad federativa
corruption_mx = corruption_mx.replace({1: 'Muy_Frecuente', 2: 'Frecuente', 3: 'Poco_Frecuente',
                                     4: 'Nada_Frecuente', 9: 'No_Sabe'})
corruption_mx.head(2)

mca = prince.MCA(n_components = 3)
mca = mca.fit(corruption_mx)

mca.eigenvalues_summary

ax = mca.plot(corruption_mx, show_row_markers = False, show_column_markers = True,
              show_row_labels = False, show_column_labels = True)
ax

ax = mca.plot(corruption_mx, show_row_markers = True, show_column_markers = False,
              show_row_labels = True, show_column_labels = False)
ax

ax = mca.plot(corruption_mx, show_row_markers = True, show_column_markers = False,
              show_row_labels = False, show_column_labels = True)
ax

"""Teniendo en cuenta lo anterior, se identificaron entidades federativas donde la percepción de la corrupción difiere significativamente. Esto se hizo para analizar posibles patrones y disparidades en la percepción de la corrupción hacia diversas instituciones públicas. Por ejemplo, el nivel promedio de percepción de corrupción en la Ciudad de México es del 96.45%, mientras que en Querétaro es del 76.51%. Se eligieron inicialmente estas entidades debido a su marcada diferencia en cuanto al nivel de percepción de la corrupción."""

corruption_cdmx_qro = corruption.iloc[:, 1:23].copy() # percepcion de la corrupcion por entidad federativa
corruption_cdmx_qro = corruption_cdmx_qro.replace({1: 'Muy_Frecuente', 2: 'Frecuente', 3: 'Poco_Frecuente',
                                     4: 'Nada_Frecuente', 9: 'No_Sabe'})
corruption_cdmx_qro = corruption_cdmx_qro.loc[(corruption_cdmx_qro['Entidad_Federativa'] == 'CDMX') | (corruption_cdmx_qro['Entidad_Federativa'] == 'QRO')] # percepcion de la corrupcion en CDMX y QRO
corruption_cdmx_qro = corruption_cdmx_qro.set_index('Entidad_Federativa')
corruption_cdmx_qro.head(2)

mca = prince.MCA(n_components = 3)
mca = mca.fit(corruption_cdmx_qro)

mca.eigenvalues_summary

ax = mca.plot(corruption_cdmx_qro, show_row_markers = True, show_column_markers = False,
              show_row_labels = True, show_column_labels = False)
ax

ax = mca.plot(corruption_cdmx_qro, show_row_markers = False, show_column_markers = True,
              show_row_labels = False, show_column_labels = True)
ax

ax = mca.plot(corruption_cdmx_qro, show_row_markers = True, show_column_markers = False,
              show_row_labels = False, show_column_labels = True)
ax

"""Posteriormente se eligieron los estados de QRO y YUC, ya que son los estados con un nivel de percepción de corrupción menor. También se consideraron la CDMX y VER, estados con el mayor nivel de percepción de corrupción, para realizar comparaciones adicionales. Esto podría proporcionar una perspectiva más amplia sobre las posibles causas o factores que influyen en los niveles de percepción de corrupción en diferentes regiones del país."""

corruption_qro_yuc = corruption.iloc[:, 1:23].copy() # percepcion de la corrupcion por entidad federativa
corruption_qro_yuc = corruption_qro_yuc.replace({1: 'Muy_Frecuente', 2: 'Frecuente', 3: 'Poco_Frecuente',
                                     4: 'Nada_Frecuente', 9: 'No_Sabe'})
corruption_qro_yuc = corruption_qro_yuc.loc[(corruption_qro_yuc['Entidad_Federativa'] == 'QRO') | (corruption_qro_yuc['Entidad_Federativa'] == 'YUC')] # percepcion de la corrupcion en QRO y YUC
corruption_qro_yuc = corruption_qro_yuc.set_index('Entidad_Federativa')
corruption_qro_yuc.head(2)

mca = prince.MCA(n_components = 3)
mca = mca.fit(corruption_qro_yuc)

mca.eigenvalues_summary

ax = mca.plot(corruption_qro_yuc, show_row_markers = True, show_column_markers = False,
              show_row_labels = True, show_column_labels = False)
ax

ax = mca.plot(corruption_qro_yuc, show_row_markers = False, show_column_markers = True,
              show_row_labels = False, show_column_labels = True)
ax

ax = mca.plot(corruption_qro_yuc, show_row_markers = True, show_column_markers = False,
              show_row_labels = False, show_column_labels = True)
ax

corruption_cdmx_ver = corruption.iloc[:, 1:23].copy() # percepcion de la corrupcion por entidad federativa
corruption_cdmx_ver = corruption_cdmx_ver.replace({1: 'Muy_Frecuente', 2: 'Frecuente', 3: 'Poco_Frecuente',
                                     4: 'Nada_Frecuente', 9: 'No_Sabe'})
corruption_cdmx_ver = corruption_cdmx_ver.loc[(corruption_cdmx_ver['Entidad_Federativa'] == 'CDMX') | (corruption_cdmx_ver['Entidad_Federativa'] == 'VER')] # percepcion de la corrupcion en CDMX y VER
corruption_cdmx_ver = corruption_cdmx_ver.set_index('Entidad_Federativa')
corruption_cdmx_ver.head(2)

mca = prince.MCA(n_components = 3)
mca = mca.fit(corruption_cdmx_ver)

mca.eigenvalues_summary

ax = mca.plot(corruption_cdmx_ver, show_row_markers = True, show_column_markers = False,
              show_row_labels = True, show_column_labels = False)
ax

ax = mca.plot(corruption_cdmx_ver, show_row_markers = False, show_column_markers = True,
              show_row_labels = False, show_column_labels = True)
ax

ax = mca.plot(corruption_cdmx_ver, show_row_markers = True, show_column_markers = False,
              show_row_labels = False, show_column_labels = True)
ax

"""Debido a la dificultad para interpretar la visualización anterior, se optó por combinar las categorías **Muy Frecuente** y **Frecuente** en una sola, indicando la **presencia** de corrupción. De manera similar, se agruparon las categorías **Nada Frecuente** y **Poco Frecuente** en una sola, indicando la **ausencia** de corrupción. Esto se hizo con el objetivo de mejorar la interpretabilidad del gráfico obtenido a partir del análisis de correspondencias múltiples.

### Percepción de la Corrupción y su Relación con la Confianza Ciudadana en las Instituciones Publicas

#### Nivel de Percepción de la Corrupción en las Instituciones Públicas
"""

id_corruption = sec_1_3_4_5_8_9_10.loc[:, ['ENT', 'UPM', 'V_SEL', 'P3_2', 'P3_3_1', 'P3_3_2', 'P3_3_3', 'P3_3_4', 'P3_3_5',
                           'P3_3_6', 'P3_3_7', 'P3_3_8', 'P3_3_9', 'P3_3_10', 'P3_3_11', 'P3_3_12', 'P3_3_13', 'P3_3_14',
                           'P3_3_15', 'P3_3_16', 'P3_3_17', 'P3_3_18', 'P3_3_19', 'P3_3_20', 'P3_3_21']].copy() # conjunto de datos con las variables relacionadas al nivel de percepcion de corrupcion hacia instituciones manteniendo variables compartidas ENT, UPM, y V_SEL

id_corruption.shape # dimensiones del conjunto de datos

id_corruption.head()

id_corruption.dtypes

id_corruption.iloc[:, list(range(3, 25))] = id_corruption.iloc[:, list(range(3, 25))].apply(pd.to_numeric, errors = 'coerce').astype('int64') # conversion de tipos de datos string a int
id_corruption.dtypes # verificar los tipos de datos del conjunto de datos

id_corruption = id_corruption.replace({1: 'Muy_Frecuente', 2: 'Frecuente', 3: 'Poco_Frecuente',
                                       4: 'Nada_Frecuente', 9: 'No_Sabe'}) # reemplazar el valor numerico por la categoria correspondiente

id_corruption.head()

id_corruption.tail()

"""#### Nivel de Confianza Ciudadana en las Instituciones Públicas"""

trust_confidence_public_institutes = sec_11.loc[:, ['ENT', 'UPM', 'V_SEL', 'P11_1_1', 'P11_1_2', 'P11_1_3', 'P11_1_4', 'P11_1_5', 'P11_1_6',
               'P11_1_7', 'P11_1_8', 'P11_1_9', 'P11_1_10', 'P11_1_11', 'P11_1_12', 'P11_1_13', 'P11_1_14',
               'P11_1_15', 'P11_1_16', 'P11_1_17', 'P11_1_18','P11_1_19', 'P11_1_20', 'P11_1_21']].copy() # conjunto de datos con las variables relacionadas al nivel de confianza hacia instituciones manteniendo variables compartidas ENT, UPM, y V_SEL

trust_confidence_public_institutes.shape # dimensiones del conjunto de datos

trust_confidence_public_institutes.head()

trust_confidence_public_institutes.dtypes

trust_confidence_public_institutes.iloc[:, list(range(3, 24))] = trust_confidence_public_institutes.iloc[:, list(range(3, 24))].apply(pd.to_numeric, errors = 'coerce').astype('int64') # conversion de tipos de datos string a int
trust_confidence_public_institutes.dtypes # verificar los tipos de datos del conjunto de datos

trust_confidence_public_institutes = trust_confidence_public_institutes.replace({1: 'Mucha_Confianza', 2: 'Poca_Confianza', 3: 'Desconfianza',
                                                                                 4: 'Mucha_Desconfianza', 5: 'No_Aplica', 9: 'No_Responde'}) # reemplazar el valor numerico por la categoria correspondiente

trust_confidence_public_institutes

"""#### Relación entre los Niveles de Percepción de la Corrupción y Confianza en las Instituciones Públicas"""

corruption_confidence_insitutes = pd.merge(id_corruption, trust_confidence_public_institutes,
                                           how = 'inner', on = ['ENT', 'UPM', 'V_SEL']) # combinar los conjuntos de datos utilizando las variables compartidas ENT, UPM, y V_SEL

corruption_confidence_insitutes.head()

corruption_confidence_insitutes.dtypes

corruption_and_confidence = corruption_confidence_insitutes.iloc[:, list(range(4, 46))].copy() # conjunto de datos con las variables relacionadas a la percepcion de la corrupcion y al nivel de confianza hacia las instituciones publicas

corruption_and_confidence.columns

corruption_and_confidence.head()

categories = ['Muy_Frecuente', 'Frecuente', 'Poco_Frecuente', 'Nada_Frecuente', 'No_Sabe',
              'Mucha_Confianza', 'Poca_Confianza', 'Desconfianza', 'Mucha_Desconfianza', 'No_Aplica', 'No_Responde'] # niveles de percepcion de la corrupcion y confianza hacias las instituciones publicas
contingency_table_corruption_confidence = pd.DataFrame(columns = categories) # no. ocurrencias de cada nivel de percepcion en las distintas instituciones publicas
contingency_table_corruption_confidence.head() # conjunto de datos vacio

for column in corruption_and_confidence.columns:
    frecuency = corruption_and_confidence[column].value_counts().reindex(categories, fill_value = 0).to_dict() # ocurrencias de los distintos niveles de percepcion de la corrupcion (categorias) para las distintas instituciones
    contingency_table_corruption_confidence = pd.concat([contingency_table_corruption_confidence, pd.DataFrame(frecuency, index = [column])]) # anadir fila (institucion) con el no. de ocurrencias para las distintas categorias (columnas)

contingency_table_corruption_confidence.dtypes # verificar los tipos de datos de la tabla de contingencia

contingency_table_corruption_confidence[categories] = contingency_table_corruption_confidence[categories].astype(int) # conversion de object a int
contingency_table_corruption_confidence.dtypes # verificar los tipos de datos de la tabla de contingencia

contingency_table_corruption_confidence.head()

contingency_table_corruption_confidence.tail()

categories = {'P3_3_1': 'Universidades', 'P3_3_2': 'Policia', 'P3_3_3': 'Hospitales', 'P3_3_4': 'Secretarias', 'P3_3_5': 'Empresarios', 'P3_3_6': 'Gubernatura', 'P3_3_7': 'Trabajo', 'P3_3_8': 'Municipio', 'P3_3_9': 'Familiares', 'P3_3_10': 'Sindicatos', 'P3_3_11': 'Vecinos', 'P3_3_12': 'Diputados_Senadores', 'P3_3_13': 'Medios_Comunicacion', 'P3_3_14': 'Intitutos_Electorales', 'P3_3_15': 'Comisiones_Derechos', 'P3_3_16': 'Escuelas_Publicas', 'P3_3_17': 'Jueces_Magistrados', 'P3_3_18': 'Insituciones_Religiosas', 'P3_3_19': 'Partidos_Politicos', 'P3_3_20': 'Ejercito_Marina', 'P3_3_21': 'Ministerio_Publico',
              'P11_1_1': 'Universidades', 'P11_1_2': 'Policia', 'P11_1_3': 'Hospitales', 'P11_1_4': 'Secretarias', 'P11_1_5': 'Empresarios', 'P11_1_6': 'Gubernatura', 'P11_1_7': 'Trabajo', 'P11_1_8': 'Municipio', 'P11_1_9': 'Familiares', 'P11_1_10': 'Sindicatos', 'P11_1_11': 'Vecinos', 'P11_1_12': 'Diputados_Senadores', 'P11_1_13': 'Medios_Comunicacion', 'P11_1_14': 'Intitutos_Electorales', 'P11_1_15': 'Comisiones_Derechos', 'P11_1_16': 'Escuelas_Publicas', 'P11_1_17': 'Jueces_Magistrados', 'P11_1_18': 'Insituciones_Religiosas', 'P11_1_19': 'Partidos_Politicos', 'P11_1_20': 'Ejercito_Marina', 'P11_1_21': 'Ministerio_Publico'} # variables y sus instituciones asociadas correspondientes

contingency_table_corruption_confidence = contingency_table_corruption_confidence.rename(categories) # reemplazar el nombre de la variable por la institucion correspondiente
contingency_table_corruption_confidence

contingency_table_corruption_confidence.columns

agg_functions = {'Muy_Frecuente': 'sum', 'Frecuente': 'sum', 'Poco_Frecuente': 'sum', 'Nada_Frecuente': 'sum',
                 'No_Sabe': 'sum', 'Mucha_Confianza': 'sum', 'Poca_Confianza': 'sum', 'Desconfianza': 'sum',
                 'Mucha_Desconfianza': 'sum', 'No_Aplica': 'sum', 'No_Responde': 'sum'}

contingency_table_corruption_confidence_updated = contingency_table_corruption_confidence.groupby(contingency_table_corruption_confidence.index).agg(agg_functions) # agrupar frecuencias de cada categoria (columnas) para cada institucion (filas)
contingency_table_corruption_confidence_updated

contingency_table_corruption_confidence_updated.dtypes # verificar los tipos de datos de la tabla de contingencia

"""#### Analisis de Correspondencia"""

ca = prince.CA(n_components = 3, n_iter = 3, copy = True,
               check_input = True, engine = 'sklearn', random_state = 0) # modelo de analisis de correspondencia
ca = ca.fit(contingency_table_corruption_confidence_updated) # ajustar el modelo a los datos

ca.eigenvalues_summary

"""Las dos primeras componentes explican más del **80% de la varianza total**."""

ca.plot(contingency_table_corruption_confidence_updated, x_component = 0, y_component = 1, show_row_markers = True,
        show_column_markers = False, show_row_labels = False, show_column_labels = True)

ca.plot(contingency_table_corruption_confidence_updated, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = False)

ca.plot(contingency_table_corruption_confidence_updated, x_component = 0, y_component = 1, show_row_markers = False,
        show_column_markers = True, show_row_labels = True, show_column_labels = True)

ca.column_contributions_.style.format('{:.0%}')

ca.row_contributions_.style.format('{:.0%}')

"""#### Análisis de Correspondencia Múltiple

Se llevó a cabo un análisis de correspondencia múltiple utilizando las variables relacionadas con el **nivel de percepción de corrupción** hacia diversas instituciones públicas y el **grado de confianza** ciudadana en las mismas, considerando los 32 estados de la República Mexicana. Esto se hizo con el objetivo de comprender la relación entre múltiples variables categóricas, como la **presencia/ausencia** de corrupción y la **confianza/desconfianza** de los ciudadanos en diferentes instituciones públicas, en varias regiones de México.

Debido a la dificultad para interpretar la visualizaciones en las secciones anteriores, se optó por combinar las categorías **Muy Frecuente** y **Frecuente** en una sola, indicando la **presencia** de corrupción. De manera similar, se agruparon las categorías **Nada Frecuente** y **Poco Frecuente** en una sola, indicando la **ausencia** de corrupción. Esto se hizo con el objetivo de mejorar la interpretabilidad del gráfico obtenido a partir del análisis de correspondencias múltiples.

##### Nivel de Percepción de Corrupción en las Instituciones Públicas de la República Mexicana
"""

id_corruption_updated = sec_1_3_4_5_8_9_10.loc[:, ['ENT', 'UPM', 'V_SEL', 'NOM_ENT', 'P3_3_1', 'P3_3_2', 'P3_3_3', 'P3_3_4', 'P3_3_5',
                        'P3_3_6', 'P3_3_7', 'P3_3_8', 'P3_3_9', 'P3_3_10', 'P3_3_11', 'P3_3_12', 'P3_3_13', 'P3_3_14',
                        'P3_3_15', 'P3_3_16', 'P3_3_17', 'P3_3_18', 'P3_3_19', 'P3_3_20', 'P3_3_21']].copy() # conjunto de datos con las variables relacionadas al nivel de percepcion de corrupcion hacia instituciones manteniendo variables compartidas ENT, UPM, y V_SEL

id_corruption_updated.iloc[:, list(range(4, 25))] = id_corruption_updated.iloc[:, list(range(4, 25))].apply(pd.to_numeric, errors = 'coerce').astype('int64') # conversion de tipos de datos string a int
id_corruption_updated = id_corruption_updated.replace({1: 'Presencia', 2: 'Presencia', 3: 'Ausencia',
                                                       4: 'Ausencia', 9: 'Indiferente'}) # reemplazar el valor numerico por la categoria correspondiente

id_corruption_updated.head(2) # nivel de confianza hacia las distintas instituciones publicas

"""##### Nivel de Confianza en las Instituciones Públicas de la República Mexicana"""

trust_confidence_public_institutes_updated = sec_11.loc[:, ['ENT', 'UPM', 'V_SEL', 'NOM_ENT', 'P11_1_1', 'P11_1_2', 'P11_1_3', 'P11_1_4', 'P11_1_5', 'P11_1_6',
                                             'P11_1_7', 'P11_1_8', 'P11_1_9', 'P11_1_10', 'P11_1_11', 'P11_1_12', 'P11_1_13', 'P11_1_14',
                                             'P11_1_15', 'P11_1_16', 'P11_1_17', 'P11_1_18','P11_1_19', 'P11_1_20', 'P11_1_21']].copy() # conjunto de datos con las variables relacionadas al nivel de confianza hacia instituciones manteniendo variables compartidas ENT, UPM, y V_SEL

trust_confidence_public_institutes_updated.iloc[:, list(range(4, 25))] = trust_confidence_public_institutes_updated.iloc[:, list(range(4, 25))].apply(pd.to_numeric, errors = 'coerce').astype('int64') # conversion de tipos de datos string a int
trust_confidence_public_institutes_updated = trust_confidence_public_institutes_updated.replace({1: 'Confianza', 2: 'Confianza', 3: 'Desconfianza',
                                                                                                 4: 'Desconfianza', 5: 'No Aplica', 9: 'Indiferente'}) # reemplazar el valor numerico por la categoria correspondiente

trust_confidence_public_institutes_updated.head(2) # nivel de confianza hacia las distintas instituciones publicas

"""##### Nivel de Percepción de Corrupción y Confianza en las Instituciones Públicas en la República Mexicana"""

corruption_confidence_insitutes_mx = pd.merge(id_corruption_updated, trust_confidence_public_institutes_updated,
                                                how = 'inner', on = ['ENT', 'UPM', 'V_SEL', 'NOM_ENT'])
corruption_confidence_insitutes_mx.head(2)

corruption_confidence_insitutes_mx = corruption_confidence_insitutes_mx.set_index('NOM_ENT')

corruption_confidence_insitutes_mx.head(2)

corruption_confidence_insitutes_mx_updated = corruption_confidence_insitutes_mx.iloc[:, 3:].astype('|S').copy() # conversion de object a str

corruption_confidence_insitutes_mx_updated.head(2)

corruption_confidence_insitutes_mx_updated.columns

institutes = ['Universidades', 'Policia', 'Hospitales', 'Secretarias', 'Empresarios', 'Gubernatura', 'Trabajo', 'Municipio', 'Familiares', 'Sindicatos', 'Vecinos', 'Diputados_Senadores', 'Medios_Comunicacion', 'Intitutos_Electorales', 'Comisiones_Derechos', 'Escuelas_Publicas', 'Jueces_Magistrados', 'Insituciones_Religiosas', 'Partidos_Politicos', 'Ejercito_Marina', 'Ministerio_Publico',
              'Universidades', 'Policia', 'Hospitales', 'Secretarias', 'Empresarios', 'Gubernatura', 'Trabajo', 'Municipio', 'Familiares', 'Sindicatos', 'Vecinos', 'Diputados_Senadores', 'Medios_Comunicacion', 'Intitutos_Electorales', 'Comisiones_Derechos', 'Escuelas_Publicas', 'Jueces_Magistrados', 'Insituciones_Religiosas', 'Partidos_Politicos', 'Ejercito_Marina', 'Ministerio_Publico'] # instituciones publicas
corruption_confidence_insitutes_mx_updated.columns = institutes # reemplazar el nombre de la variable por la institucion correspondiente

mca = prince.MCA(n_components = 3)
mca = mca.fit(corruption_confidence_insitutes_mx_updated)

mca.eigenvalues_summary

ax = mca.plot(corruption_confidence_insitutes_mx_updated, show_row_markers = True, show_column_markers = False,
              show_row_labels = True, show_column_labels = False)
ax

ax = mca.plot(corruption_confidence_insitutes_mx_updated, show_row_markers = False, show_column_markers = True,
              show_row_labels = False, show_column_labels = True)
ax

ax = mca.plot(corruption_confidence_insitutes_mx_updated, show_row_markers = True, show_column_markers = False,
              show_row_labels = False, show_column_labels = True)
ax

corruption_confidence_insitutes_mx.head(2)

corruption_confidence_insitutes_cdmx_qro = corruption_confidence_insitutes_mx.loc[(corruption_confidence_insitutes_mx['ENT'] == '09') | (corruption_confidence_insitutes_mx['ENT'] == '22')] # percepcion de la corrupcion y confianza en CDMX y VER
corruption_confidence_insitutes_cdmx_qro.head(2)

corruption_confidence_insitutes_cdmx_qro_updated = corruption_confidence_insitutes_cdmx_qro.iloc[:, 3:].astype('|S').copy() # conversion de object a str

institutes = ['Universidades', 'Policia', 'Hospitales', 'Secretarias', 'Empresarios', 'Gubernatura', 'Trabajo', 'Municipio', 'Familiares', 'Sindicatos', 'Vecinos', 'Diputados_Senadores', 'Medios_Comunicacion', 'Intitutos_Electorales', 'Comisiones_Derechos', 'Escuelas_Publicas', 'Jueces_Magistrados', 'Insituciones_Religiosas', 'Partidos_Politicos', 'Ejercito_Marina', 'Ministerio_Publico',
              'Universidades', 'Policia', 'Hospitales', 'Secretarias', 'Empresarios', 'Gubernatura', 'Trabajo', 'Municipio', 'Familiares', 'Sindicatos', 'Vecinos', 'Diputados_Senadores', 'Medios_Comunicacion', 'Intitutos_Electorales', 'Comisiones_Derechos', 'Escuelas_Publicas', 'Jueces_Magistrados', 'Insituciones_Religiosas', 'Partidos_Politicos', 'Ejercito_Marina', 'Ministerio_Publico'] # instituciones publicas
corruption_confidence_insitutes_cdmx_qro_updated.columns = institutes # reemplazar el nombre de la variable por la institucion correspondiente

mca = prince.MCA(n_components = 3)
mca = mca.fit(corruption_confidence_insitutes_cdmx_qro_updated)

mca.eigenvalues_summary

ax = mca.plot(corruption_confidence_insitutes_cdmx_qro_updated, show_row_markers = True, show_column_markers = False,
              show_row_labels = True, show_column_labels = False)
ax

ax = mca.plot(corruption_confidence_insitutes_cdmx_qro_updated, show_row_markers = False, show_column_markers = True,
              show_row_labels = False, show_column_labels = True)
ax

ax = mca.plot(corruption_confidence_insitutes_cdmx_qro_updated, show_row_markers = True, show_column_markers = True,
              show_row_labels = False, show_column_labels = False)
ax

ax = mca.plot(corruption_confidence_insitutes_cdmx_qro_updated, show_row_markers = True, show_column_markers = False,
              show_row_labels = False, show_column_labels = True)
ax

"""## Evaluación de Servicios Básicos: Nivel de Satisfacción Ciudadana"""

basic_services = sec_1_3_4_5_8_9_10.loc[:, ['NOM_ENT', 'P4_1B', 'P4_2B', 'P4_5B', 'P4_6B',
                                            'P4_7B', 'P5_7B', 'P5_2B', 'P5_4B', 'P5_5B', 'P5_6B']].copy() # columnas de interes correspondientes a la evaluacion de los servicios basicos: agua, policia, luz, transporte publico, salud (IMMS e ISSTE)

services = ['NOM_ENT', 'Agua', 'Drenaje', 'Recoleccion Basura', 'Policia', 'Calles y Avenidas', 'Luz', 'Educacion', 'IMSS', 'ISSTE', 'Seguro Popular'] # servicios publicos basicos
basic_services.columns = services # redefinir las columnas para mejor la legibilidad de los graficos

basic_services.shape

basic_services.head()

basic_services.dtypes

(basic_services == '').sum() # no. valores vacíos (blancos) por columna

"""Los datos relacionados con los servicios básicos de salud, tales como IMSS, ISSSTE y Seguro Popular, muestran una carencia significativa en su mayoría, con valores faltantes que impiden obtener información precisa sobre estos servicios. Se necesita un análisis detallado de la información disponible sobre los trámites relacionados con los servicios de salud para comprender mejor la situación y posiblemente abordar las deficiencias en la recopilación de datos.

####  Imputación de Datos Utilizando el Enfoque K-Vecinos Más Cercanos
"""

basic_services_imputed = basic_services.iloc[:, 1:7].copy() # filtrar servicios
basic_services_imputed.replace('', np.nan, inplace = True) # reemplazar valores vacios con valores NaN

basic_services_imputed = basic_services_imputed.apply(pd.to_numeric, errors = 'coerce') # convertir valores NaN a valores np.nan para poder trabajar con la funcion KNN Imputer

basic_services_imputed.head()

(basic_services_imputed == '').sum() # no. valores vacíos (blancos) por columna

imputer = KNNImputer(n_neighbors = 2, weights = 'uniform')
basic_services_updated = pd.DataFrame(imputer.fit_transform(basic_services_imputed), columns = basic_services_imputed.columns)

basic_services_updated.head()

basic_services_updated.dtypes # verificar los tipos de datos de la tabla de contingencia

basic_services_updated = basic_services_updated.astype(int) # conversion de datos tipo float a int
basic_services_updated['NOM_ENT'] = basic_services['NOM_ENT'] # anadir columna con los nombres de las entidades federativas correspondientes a cada observacion
basic_services_updated.head()

"""#### Nivel de Satisfacción General con los Servicios Básicos por Entidad Federativa"""

service_quality_by_state = basic_services_updated.groupby(['NOM_ENT']).sum().copy() # suma de todas las calificaciones por servicio para cada uno de las entidades federativas
service_quality_by_state.head()

n = basic_services_updated['NOM_ENT'].value_counts() # no. total de observaciones por estado

average_service_quality = service_quality_by_state.div(n, axis = 0).round(4).copy() # dividir entradas por el no. total de observaciones para obtener la calificacion promedio de cada servicio para cada entidad federativa
average_service_quality['Calificacion General'] = (average_service_quality.mean(axis = 1)*10).round(4) # calificacion total por entidad federativa basandose en los puntajes obtenidos de cada uno de sus servicios
average_service_quality.head()

barplot_services = average_service_quality.reset_index().rename(columns = {'NOM_ENT': 'Entidad Federativa'}).copy()

pio.renderers.default = 'iframe'
fig = px.bar(barplot_services, x = 'Entidad Federativa', y = 'Calificacion General')
fig.update_layout(xaxis = {'categoryorder':'total descending'})
fig.update_traces(marker_color = 'steelblue', marker_line_color = 'slategray', marker_line_width = 1.5, opacity = 0.6)
fig.update_layout(title_text = 'Nivel de Satisfacción General con los Servicios Básicos por Entidad Federativa')
fig.show()

"""Existe una variabilidad significativa en la percepción de los servicios básicos entre las diferentes entidades federativas. Algunas estados, como **Nuevo León** (NL) y **Colima** (COL), tienen puntajes más altos, lo que sugiere una **mejor satisfacción general** con los servicios básicos proporcionados. Por otro lado, entidades como **Guerrero** (GRO) y **Chiapas** (CHIS) muestran puntajes más bajos, lo que indica una **menor satisfacción**.

#### Distribución Geográfica de la Satisfacción Percibida con los Servicios Básicos en la República Mexicana
"""

services_data = average_service_quality.reset_index().copy()
services_data = services_data.loc[:, ['NOM_ENT', 'Calificacion General']] # columnas de interes: entidades federativas y calificacion general de los servicios por entidad federativa
names = ['state', 'percent']
services_data.columns = names

services_satisfaction_map = pd.merge(geographical_data_mx, services_data, how = 'inner', on = ['state']) # unir conjunto de datos geograficos con el conjunto de datos de la calidad de los servicios basicos apartir de la columna compartida 'state'

services_satisfaction_map.head(2)

services_satisfaction_map['percent'] = services_satisfaction_map['percent'].astype(float)

services_satisfaction_map.dtypes

ax = services_satisfaction_map.plot(column = 'percent', cmap = 'PuBu', legend = True,
                                    legend_kwds = {"label": "Nivel de Satisfacción General con los Servicios Básicos", "orientation": "horizontal"})
ax.set_axis_off()
fig = ax.get_figure()
fig.savefig('NivelSatisfacciónServicios.png')

"""Las áreas con colores más oscuros indican una mayor satisfacción, mientras que las áreas más claras sugieren una menor satisfacción. Estados, como **Nuevo León** y **Colima**, aparecen en tonos más oscuros, indicando **altos niveles de satisfacción**, mientras que estados como **Guerrero** y **Chiapas** muestran colores más claros, lo que sugiere **niveles más bajos de satisfacción**. Este mapa visualiza de manera clara las diferencias regionales en la percepción de los servicios básicos y podría ser útil para identificar áreas que requieren una mayor atención en términos de mejora de la calidad de los servicios.

#### Nivel de Percepción de la Corrupción y Satisfacción General con los Servicios Básicos por Entidad Federativa
"""

barplot_corruption_services = average_level_corruption.copy()
barplot_corruption_services['Calificacion General'] = (average_service_quality['Calificacion General'])
barplot_corruption_services = barplot_corruption_services.sort_values('Porcentaje', ascending = False).reset_index()
barplot_corruption_services.head()

pio.renderers.default = 'iframe'
fig = go.Figure()
fig.add_trace(go.Bar(
    x = barplot_corruption_services['Entidad_Federativa'],
    y = barplot_corruption_services['Porcentaje'],
    name = 'Porcentaje de Corrupción',
    marker_color = 'indianred',
    marker_line_color = 'brown',
    marker_line_width = 1.5,
    opacity = 0.6
))
fig.add_trace(go.Bar(
    x = barplot_corruption_services['Entidad_Federativa'],
    y = barplot_corruption_services['Calificacion General'],
    name = 'Nivel de Satisfacción',
    marker_color = 'steelblue',
    marker_line_color = 'slategray',
    marker_line_width = 1.5,
    opacity = 0.8
))
fig.update_layout(title_text = 'Nivel de Percepción de la Corrupción y Nivel de Satisfacción General con los Servicios Básicos por Entidad Federativa')
fig.update_layout(barmode = 'group', bargroupgap = 0.10, bargap = 0.20)
bargroupgap=0.1
fig.show()

"""No parece haber una relación clara entre la percepción de corrupción y la calificación de los servicios. En algunas entidades con altos niveles de corrupción, la calificación de los servicios es alta, mientras que en otras entidades con bajos niveles de corrupción, la calificación de los servicios puede ser baja.

## Experiencias con Pagos, Tramites y Solicitudes de Servicios de Salud

Según el diccionario de datos de la base de datos, la variable *N_TRA* especifica el tipo de trámite registrado. Las claves **07** y **08** corresponden a trámites realizados para acceder a los servicios de salud.
"""

services_and_corruption = sec_1_3_4_5_8_9_10.loc[:, ['ENT', 'NOM_ENT', 'UPM', 'V_SEL', 'P8_2', 'P9_1', 'P9_7', 'P9_8']].copy() # columnas de interes correspondientes a los casos de corrupcion reportados por los ciudadanos

services_provided = sec_7.loc[:, ['ENT', 'NOM_ENT', 'UPM', 'V_SEL', 'N_TRA', 'P7_4_1', 'P7_4_2', 'P7_4_3', 'P7_4_4', 'P7_4_5',
                                 'P7_4_6', 'P7_4_7', 'P7_4_8', 'P7_4_9', 'P7_4_10', 'P7_4_11']] # columnas de interes correspondientes a los problemas principales que enfrenta la poblacion al momento de realizar un tramite de algun servicio

services_provided = services_provided.set_index('NOM_ENT')
services_provided.head()

services_provided.dtypes

health_services_updated = services_provided.loc[(services_provided['N_TRA'] == '07') | (services_provided['N_TRA'] == '08')].copy()

health_services_updated = health_services_updated.iloc[:, 4:]
health_services_updated.head()

health_services_updated.shape

health_services_updated = health_services_updated.replace({'1': 'Si', '2': 'No', '3': 'No Aplica',
                                           '9': 'Indiferente', 'b': 'Sin Informacion'}) # reemplazar el valor numerico por la categoria correspondiente

issues_related_services = ['Largas Filas', 'Falta de Claridad', 'Requisitos Excesivos', 'Ventanilla Incorrecta', 'Informacion Erronea',
              'Fallas Telefonicas', 'Fallas Servicio en Linea', 'Lejania del Sitio', 'Costo Excesivo', 'Horario Restringido', 'Otro'] # instituciones publicas
health_services_updated.columns = issues_related_services

health_services_updated

"""#### Análisis de Correspondencia Múltiple

Se llevó a cabo un análisis de correspondencia múltiple utilizando el conjunto de datos *health_services_updated* con el objetivo de obtener información sobre las relaciones entre los distintos tipos de problemas y los estados. Información que podría contribuir a mejorar la eficiencia y efectividad de los **servicios de salud** en diversas regiones, además de identificar patrones en la aparición de diferentes tipos de problemas en los estados considerados.
"""

mca = prince.MCA(n_components = 3)
mca = mca.fit(health_services_updated)

mca.eigenvalues_summary

ax = mca.plot(health_services_updated, show_row_markers = True, show_column_markers = False,
              show_row_labels = True, show_column_labels = False)
ax

ax = mca.plot(health_services_updated, show_row_markers = False, show_column_markers = True,
              show_row_labels = False, show_column_labels = True)
ax

ax = mca.plot(health_services_updated, show_row_markers = True, show_column_markers = False,
              show_row_labels = False, show_column_labels = True)
ax

ax = mca.plot(health_services_updated, show_row_markers = True, show_column_markers = True,
              show_row_labels = False, show_column_labels = False)
ax

"""#### Problemas en el Pago, Trámite o Solicitud de Servicios de Salud"""

categories = ['Si', 'No', 'No Aplica', 'Indiferente', 'Sin Informacion'] # posibles respuestas hacia la problematica en cuestion
contingency_table_health_services = pd.DataFrame(columns = categories) # no. ocurrencias de cada nivel de percepcion en las distintas instituciones publicas
contingency_table_health_services.head() # conjunto de datos vacio

for column in health_services_updated.columns:
    frecuency = health_services_updated[column].value_counts().reindex(categories, fill_value = 0).to_dict() # ocurrencias de los distintos niveles de percepcion de la corrupcion (categorias) para las distintas instituciones
    contingency_table_health_services = pd.concat([contingency_table_health_services, pd.DataFrame(frecuency, index = [column])]) # anadir fila (institucion) con el no. de ocurrencias para las distintas categorias (columnas)

contingency_table_health_services.dtypes

contingency_table_health_services[categories] = contingency_table_health_services[categories].astype(int) # conversion de object a int
contingency_table_health_services.dtypes # verificar los tipos de datos de la tabla de contingencia

contingency_table_health_services

contingency_table_health_services_updated = contingency_table_health_services.iloc[:, :2]
contingency_table_health_services_updated['Total'] = contingency_table_health_services_updated.sum(axis = 1) # agregar columna con el total de entradas por fila

contingency_table_health_services_updated

contingency_table_health_services_updated['% Si'] = (contingency_table_health_services_updated['Si'] / contingency_table_health_services_updated['Total']) * 100
contingency_table_health_services_updated['% No'] = (contingency_table_health_services_updated['No'] / contingency_table_health_services_updated['Total']) * 100
contingency_table_health_services_updated = contingency_table_health_services_updated.reset_index().sort_values(by = '% Si', ascending = False)

contingency_table_health_services_updated

pio.renderers.default = 'iframe'

colors = ['lightslategray'] * 11
colors[0] = 'brown'

fig = go.Figure()
fig.add_trace(go.Bar(
    x = contingency_table_health_services_updated['index'],
    y = contingency_table_health_services_updated['% Si'],
    name = 'Frecuencia de Ocurrencia del Problema',
    marker_color = colors,
    opacity = 0.6
))
fig.update_layout(title_text = 'Problemas en el Pago, Trámite o Solicitud de Servicios de Salud')
fig.update_layout(barmode = 'group', bargroupgap = 0.10, bargap = 0.20)
bargroupgap=0.1
fig.show()

"""El problema predominante en los trámites relacionados con servicios de salud son las **largas filas** al momento de realizarlos. Esto es de gran importancia, ya que el tiempo de espera es crucial en el ámbito de la salud. Las largas filas podrían influir en la decisión de los ciudadanos de solicitar el servicio, lo que, a su vez, podría llevarlos a optar por atención privada en lugar de los servicios de salud pública."""

no_yes = contingency_table_health_services_updated['Si'].sum() # no. total de respuestas afirmativas
no_no = contingency_table_health_services_updated['No'].sum() # no. total de respuestas negativas
total_no_observations = no_yes + no_no # no. total de respuestas

ypercent = (no_yes / total_no_observations) * 100
npercent = (no_no / total_no_observations) * 100

data = {'Enfrentaron Problemas': ['Sí', 'No'], 'Porcentaje': [ypercent, npercent]}

summary_health_services = pd.DataFrame(data)
summary_health_services

colors = ['lightslategray'] * 2
colors[1] = 'lightslategray'

fig = go.Figure(data=[go.Bar(
    x = ['Si', 'No'],
    y = [14.871735, 85.128265],
    marker_color = colors, marker_line_width = 1.5, opacity = 0.6
)])
fig.update_layout(title_text = 'Porcentaje de Personas que Enfrentaron  Problemas con Pagos, Trámites y Solicitudes de Servicios de Salud')

"""Del total de pagos, trámites o solicitudes de servicios de salud realizados por los usuarios, aproximadamente el 15% de ellos experimentaron algún tipo de problema durante el proceso. El más común de estos inconvenientes fue el de **largas filas**, representando un 47% del total. Son necesarios análisis adicionales para determinar las causas que explican la falta de información respecto al nivel de satisfacción de los ciudadanos con los servicios de salud

## Experiencias con Pagos, Trámites y Solicitudes de Servicios Públicos
"""

services_provided = services_provided.replace({'1': 'Si', '2': 'No', '3': 'No Aplica',
                                           '9': 'Indiferente', 'b': 'Sin Informacion'})
services_provided

services_updated = services_provided.loc[((services_provided['N_TRA'] != '20') | (services_provided['N_TRA'] == '19')) & (services_provided['N_TRA'] != '21') &
                                         ((services_provided['N_TRA'] != '22a') & (services_provided['N_TRA'] != '22b') & (services_provided['N_TRA'] != '22c') & (services_provided['N_TRA'] != '22d'))].copy() # excluir trámites realizados por medios telefónicos

services_updated

services_updated = services_updated.iloc[:, 4:]
services_updated.head()

issues_related_services = ['Largas Filas', 'Falta de Claridad', 'Requisitos Excesivos', 'Ventanilla Incorrecta', 'Informacion Erronea',
              'Fallas Telefonicas', 'Fallas Servicio en Linea', 'Lejania del Sitio', 'Costo Excesivo', 'Horario Restringido', 'Otro'] # instituciones publicas
services_updated.columns = issues_related_services

services_updated

"""#### Análisis de Correspondencia Múltiple

Se llevó a cabo un análisis de correspondencia múltiple utilizando el conjunto de datos *services_updated* con el objetivo de obtener información sobre las relaciones entre los distintos tipos de problemas y los estados. Información que podría contribuir a mejorar la eficiencia y efectividad de los **servicios públicos** en diversas regiones, además de identificar patrones en la aparición de diferentes tipos de problemas en los estados considerados.
"""

mca = prince.MCA(n_components = 3)
mca = mca.fit(services_updated)

mca.eigenvalues_summary

ax = mca.plot(services_updated, show_row_markers = True, show_column_markers = False,
              show_row_labels = True, show_column_labels = False)
ax

ax = mca.plot(services_updated, show_row_markers = False, show_column_markers = True,
              show_row_labels = False, show_column_labels = True)
ax

ax = mca.plot(services_updated, show_row_markers = True, show_column_markers = False,
              show_row_labels = False, show_column_labels = True)
ax

ax = mca.plot(services_updated, show_row_markers = True, show_column_markers = True,
              show_row_labels = False, show_column_labels = False)
ax

"""#### Problemas con Pagos, Trámites y Solicitudes de Servicios Públicos"""

categories = ['Si', 'No', 'No Aplica', 'Indiferente', 'Sin Informacion'] # posibles respuestas hacia la problematica en cuestion
contingency_table_issues_related_services = pd.DataFrame(columns = categories) # no. ocurrencias de cada nivel de percepcion en las distintas instituciones publicas
contingency_table_issues_related_services.head() # conjunto de datos vacio

for column in services_updated.columns:
    frecuency = services_updated[column].value_counts().reindex(categories, fill_value = 0).to_dict() # ocurrencias de los distintos niveles de percepcion de la corrupcion (categorias) para las distintas instituciones
    contingency_table_issues_related_services = pd.concat([contingency_table_issues_related_services, pd.DataFrame(frecuency, index = [column])]) # anadir fila (institucion) con el no. de ocurrencias para las distintas categorias (columnas)

contingency_table_issues_related_services[categories] = contingency_table_issues_related_services[categories].astype(int) # conversion de object a int
contingency_table_issues_related_services.dtypes # verificar los tipos de datos de la tabla de contingencia

contingency_table_issues_related_services = contingency_table_issues_related_services.iloc[:, :2]
contingency_table_issues_related_services['Total'] = contingency_table_issues_related_services.sum(axis = 1) # agregar columna con el total de entradas por fila

contingency_table_issues_related_services['% Si'] = (contingency_table_issues_related_services['Si'] / contingency_table_issues_related_services['Total']) * 100
contingency_table_issues_related_services['% No'] = (contingency_table_issues_related_services['No'] / contingency_table_issues_related_services['Total']) * 100
contingency_table_issues_related_services = contingency_table_issues_related_services.reset_index().sort_values(by = '% Si', ascending = False)

contingency_table_issues_related_services

pio.renderers.default = 'iframe'

colors = ['lightslategray'] * 11
colors[0] = 'brown'
colors[1] = 'brown'
colors[2] = 'brown'

fig = go.Figure()
fig.add_trace(go.Bar(
    x = contingency_table_issues_related_services['index'],
    y = contingency_table_issues_related_services['% Si'],
    name = 'Frecuencia de Ocurrencia del Problema',
    marker_color = colors,
    opacity = 0.6
))

fig.update_layout(title_text = 'Problemas en el Pago, Trámite o Solicitud de Servicios Públicos')
fig.update_layout(barmode = 'group', bargroupgap = 0.10, bargap = 0.20)
bargroupgap=0.1
fig.show()

"""El problema predominante en los pagos, trámites o solicitudes de servicios públicos es la espera en **largas filas** al momento de realizarlos. Le sigue una **falta de claridad** en los requisitos y la existencia de **horarios restringidos**. Esto es de vital importancia, ya que la mayoría de la población mexicana no cuenta con el tiempo necesario para afrontar largos períodos de espera durante los breves horarios de atención, generalmente limitados a días laborables de 8 am a 3 pm, lo que choca con los horarios laborales habituales de la ciudadanía.

El segundo problema más común es la **falta de claridad** en los requisitos solicitados, lo cual está relacionado con lo mencionado anteriormente. Dado que los días disponibles para resolver este tipo de problemas son limitados, el rechazo de un trámite debido a un requisito erróneo puede convertirse en un inconveniente que requiere atención en la mayoría de las instituciones públicas del país.
"""