# Baseline Models in Classification

# A baseline model is a simple model used to predict the outcome of data. It serves as a starting point for analysis, it allows to assess the performance of more complex models and the impact of additional features.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn.dummy import DummyRegressor
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression 
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis

X_train = pd.read_csv('/home/aspphem/Desktop/MCE/DataScience/T3/SuppMaterial/mnist/mnist_Xtrain.csv', header = None).to_numpy() # training data set 
y_train = pd.read_csv('/home/aspphem/Desktop/MCE/DataScience/T3/SuppMaterial/mnist/mnist_Ytrain.csv', header = None).to_numpy() # set of labels to all the data in train set

X_test = pd.read_csv('/home/aspphem/Desktop/MCE/DataScience/T3/SuppMaterial/mnist/mnist_Xtest.csv', header = None).to_numpy() # test data set
y_test = pd.read_csv('/home/aspphem/Desktop/MCE/DataScience/T3/SuppMaterial/mnist/mnist_Ytest.csv', header = None).to_numpy() # set of labels to all the data in test set

print(X_train[0], X_train.shape) # first element in the X train set; X train dimensions; (6000, 784)

print(y_train[0], y_train.shape) # first element in the y train set; y train dimensions
print(np.squeeze(y_train)) # remove single-dimensional entries from the shape of an array; it returns an array with the same data but reshaped dimensions
print(pd.get_dummies(np.squeeze(y_train))) # convert categorical data into dummy (indicator) variables, which are binary variables indicating the presence of a particular category of value
print(pd.get_dummies(np.squeeze(y_train)).shape) # (6000 rows, 10 columns)

def baseline_classification_model(X_train, y_train, X_test, y_test):
    y_train_transformed = pd.get_dummies(np.squeeze(y_train)) # since the range of integers in y train set is from 0 to 9, pd.get_dummies will create 10 columns, each representing one of these integers and assign a 1 to the corresponding column for each element in the array (e.g. y_train[0] = (0, 0, 0, 0, 0, 0, 1, 0, 0))
    
    n, k = y_train_transformed.shape # no. samples and classes in train set; (6000, 10)
    n_test, k_test = y_test.shape # no. samples and classes in test set; (1000, 1)
   
    test_pred = np.zeros((n_test, k)) # matrices to store clasification predictions
    
    regression_model = LinearRegression(n_jobs = -1) # ordinary least squares linear regression
    
    reg = regression_model.fit(X_train, y_train_transformed) # fit linear model
    test_pred = reg.predict(X_test) # predict using the linear model
        
    print("Classification Evaluation Metrics")
    y_predict = np.argmax(test_pred, axis = 1) # returns the indices of the maximum values along an axis; classification rule
    print(metrics.classification_report(y_test, y_predict)) # main classification metrics

    disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_predict, cmap = 'cividis')
    disp.figure_.suptitle("Confusion Matrix Baseline Classification Model") # true digits values and predicted digit values
    print(f"Confusion Matrix:\n{disp.confusion_matrix}")
    plt.show()

baseline_evaluation_metrics = baseline_classification_model(X_train, y_train, X_test, y_test)
print(baseline_evaluation_metrics)

def LDA_classification_model(X_train, y_train, X_test, y_test):
    lda = LinearDiscriminantAnalysis(solver = 'svd', store_covariance = True) # linear discriminant analysis model; a classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes' rule; the model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix
    lda.fit(X_train, y_train) # fit the linear discriminant analysis model
        
    print("Classification Evaluation Metrics")
    y_predict = lda.predict(X_test) # predict class labels for samples in X
    print(metrics.classification_report(y_test, y_predict)) # main classification metrics

    disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_predict, cmap = 'cividis')
    disp.figure_.suptitle("Confusion Matrix LDA Classification Model") # true digits values and predicted digit values
    print(f"Confusion Matrix:\n{disp.confusion_matrix}")
    plt.show()

LDA_evaluation_metrics = LDA_classification_model(X_train, y_train, X_test, y_test)
print(LDA_evaluation_metrics)


def QDA_classification_model(X_train, y_train, X_test, y_test):
    qda = QuadraticDiscriminantAnalysis(store_covariance = True) # quadratic discriminant analysis model; a classifier with a quadratic decision boundary, generated by fitting class conditional densities to data and using Bayes' rule; the model fits a Gaussian density to each class
    qda.fit(X_train, y_train) # fit the quadratic discriminant analysis model
        
    print("Classification Evaluation Metrics")
    y_predict = qda.predict(X_test) # predict class labels for samples in X
    print(metrics.classification_report(y_test, y_predict)) # main classification metrics

    disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_predict, cmap = 'cividis')
    disp.figure_.suptitle("Confusion Matrix QDA Classification Model") # true digits values and predicted digit values
    print(f"Confusion Matrix:\n{disp.confusion_matrix}")
    plt.show()

QDA_evaluation_metrics = QDA_classification_model(X_train, y_train, X_test, y_test)
print(QDA_evaluation_metrics)

